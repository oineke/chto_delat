{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2433d0f1-8024-4b7f-bbef-af55252c74de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,subprocess\n",
    "pkgs=[\"autogluon.tabular==1.4.0\",\"catboost==1.2.8\",\"tqdm\"]\n",
    "subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\"]+pkgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10c8b5-1721-46fb-9df3-8ef0d8c52171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a679f445-f1a1-439d-98e7-c8d9d4c6fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "from catboost import CatBoostRegressor,Pool\n",
    "from catboost.utils import get_gpu_device_count\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "path = Path(\".\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275b3318-8eb5-4a9e-88e8-849c3e610a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path/\"train_home.csv\")\n",
    "test = pd.read_csv(path/\"test_home.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2082ea7a-5081-49d0-81e4-26449b5801fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0500cdf-a01f-4afa-b81c-57096632d45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
       "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
       "...          ...       ...  ...         ...      ...    ...    ...   \n",
       "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0      6    2010        WD         Normal  \n",
       "1           Gar2   12500      6    2010        WD         Normal  \n",
       "2            NaN       0      3    2010        WD         Normal  \n",
       "3            NaN       0      6    2010        WD         Normal  \n",
       "4            NaN       0      1    2010        WD         Normal  \n",
       "...          ...     ...    ...     ...       ...            ...  \n",
       "1454         NaN       0      6    2006        WD         Normal  \n",
       "1455         NaN       0      4    2006        WD        Abnorml  \n",
       "1456         NaN       0      9    2006        WD        Abnorml  \n",
       "1457        Shed     700      7    2006        WD         Normal  \n",
       "1458         NaN       0     11    2006        WD         Normal  \n",
       "\n",
       "[1459 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb01c39-b8e8-43dc-a67c-ec81092f8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"SalePrice\"  # или как называется таргет в новом датасете\n",
    "feature_cols = [c for c in train.columns if c != target_col and c in test.columns]\n",
    "\n",
    "X = train[feature_cols]\n",
    "y = train[target_col].values\n",
    "X_test = test[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1890e6-83d0-4c67-b7d6-9b14b9b89c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До автофичей: (1460, 80)\n",
      "Число исходных фич: 80\n"
     ]
    }
   ],
   "source": [
    "print(\"До автофичей:\", X.shape)          # (41105, N_исходных_фич)\n",
    "print(\"Число исходных фич:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb3df2cf-72ae-4af4-a57e-11dc67300376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Int features without null values at train time contain null values at inference time! Imputing nulls to 0. To avoid this, pass the features as floats during fit!\n",
      "WARNING: Int features with nulls: ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80) (1459, 80)\n",
      "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'Street', 'Utilities',\n",
      "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
      "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'CentralAir',\n",
      "       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
      "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
      "       'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "\n",
    "fg = AutoMLPipelineFeatureGenerator(\n",
    "    enable_numeric_features=True,\n",
    "    enable_categorical_features=True,\n",
    "    enable_datetime_features=True,\n",
    "    enable_text_special_features=True,\n",
    "    enable_text_ngram_features=True,\n",
    "    enable_raw_text_features=False,\n",
    ")\n",
    "\n",
    "X_tr_feat = fg.fit_transform(X=X, y=y)\n",
    "X_te_feat = fg.transform(X_test)\n",
    "\n",
    "print(X_tr_feat.shape, X_te_feat.shape)\n",
    "print(X_tr_feat.columns[:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2728437a-c174-4234-8dd4-7186b85d6d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После автофичей: (1460, 80)\n",
      "Число фич после генерации: 80\n"
     ]
    }
   ],
   "source": [
    "print(\"После автофичей:\", X_tr_feat.shape)   # (41105, 916)\n",
    "print(\"Число фич после генерации:\", X_tr_feat.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677f5db2-cb31-4898-8b4c-e3b7a9e931f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: /venv/main/bin/python\n",
      "catboost version: 1.2.8\n",
      "GPU devices seen by catboost: 1\n"
     ]
    }
   ],
   "source": [
    "from catboost.utils import get_gpu_device_count\n",
    "import catboost, sys\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"catboost version:\", catboost.__version__)\n",
    "print(\"GPU devices seen by catboost:\", get_gpu_device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef3d256-65b6-47d6-8367-d28474cb00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категориальных колонок: 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cat_cols = [\n",
    "    c for c in X_tr_feat.columns\n",
    "    if str(X_tr_feat[c].dtype) in (\"category\", \"object\")\n",
    "]\n",
    "\n",
    "for c in cat_cols:\n",
    "    X_tr_feat[c] = X_tr_feat[c].astype(str).replace({\"nan\": \"missing\"}).fillna(\"missing\")\n",
    "    if c in X_te_feat.columns:\n",
    "        X_te_feat[c] = X_te_feat[c].astype(str).replace({\"nan\": \"missing\"}).fillna(\"missing\")\n",
    "\n",
    "print(\"Категориальных колонок:\", len(cat_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1570d3ee-e78a-4434-a730-d30b13409ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 cat_features\n"
     ]
    }
   ],
   "source": [
    "cat_features = [\n",
    "    c for c in X_tr_feat.columns\n",
    "    if str(X_tr_feat[c].dtype) in (\"object\",)  # теперь всё строковое\n",
    "]\n",
    "print(len(cat_features), \"cat_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb16849-4758-4eed-89d9-8160a659592d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e03b40-02e8-46e9-bfcb-df6361bb16a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU sanity fit (300 iters on 1000 rows) ===\n",
      "0:\tlearn: 79822.0184128\ttotal: 23.3ms\tremaining: 6.97s\n",
      "50:\tlearn: 28951.1496753\ttotal: 974ms\tremaining: 4.76s\n",
      "100:\tlearn: 21136.8504901\ttotal: 1.94s\tremaining: 3.81s\n",
      "150:\tlearn: 18114.3798295\ttotal: 2.87s\tremaining: 2.84s\n",
      "200:\tlearn: 15758.4885529\ttotal: 3.83s\tremaining: 1.89s\n",
      "250:\tlearn: 14344.2256402\ttotal: 4.79s\tremaining: 935ms\n",
      "299:\tlearn: 13164.8370247\ttotal: 5.62s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fd0cf6f2650>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "idx = np.arange(len(X_tr_feat))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx)\n",
    "small_idx = idx[:1000]\n",
    "\n",
    "X_small = X_tr_feat.iloc[small_idx]\n",
    "y_small = y[small_idx]\n",
    "\n",
    "train_pool = Pool(X_small, y_small, cat_features=cat_features)\n",
    "\n",
    "model_gpu_test = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    iterations=300,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    task_type=\"GPU\",\n",
    "    devices=\"0\",\n",
    "    verbose=50,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "print(\"=== GPU sanity fit (300 iters on 1000 rows) ===\")\n",
    "model_gpu_test.fit(train_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a28a7b65-8e5d-40c7-9495-a1faee436bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_features count: 40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for c in X_tr_feat.columns:\n",
    "    if X_tr_feat[c].dtype == \"object\":\n",
    "        X_tr_feat[c] = X_tr_feat[c].fillna(\"missing\").astype(str)\n",
    "        if c in X_te_feat.columns:\n",
    "            X_te_feat[c] = X_te_feat[c].fillna(\"missing\").astype(str)\n",
    "    else:\n",
    "        X_tr_feat[c] = pd.to_numeric(X_tr_feat[c], errors=\"coerce\")\n",
    "        if c in X_te_feat.columns:\n",
    "            X_te_feat[c] = pd.to_numeric(X_te_feat[c], errors=\"coerce\")\n",
    "\n",
    "cat_features = [\n",
    "    i for i, c in enumerate(X_tr_feat.columns)\n",
    "    if X_tr_feat[c].dtype == \"object\"\n",
    "]\n",
    "\n",
    "print(\"cat_features count:\", len(cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ae418-4203-44dc-a557-99585dd29058",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''надо поменять вообще было функцию на MAE для этой соревы но я проебался малек'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "049be6d5-42a9-46c2-82c6-d296546b7072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3dd73250ee439fb87612061771a4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "0:\tlearn: 76701.9648263\ttest: 87085.5667994\tbest: 87085.5667994 (0)\ttotal: 39ms\tremaining: 1m 56s\n",
      "200:\tlearn: 31491.7596597\ttest: 40329.7623320\tbest: 40329.7623320 (200)\ttotal: 8.12s\tremaining: 1m 53s\n",
      "400:\tlearn: 23528.1093838\ttest: 32419.3022159\tbest: 32419.3022159 (400)\ttotal: 15.8s\tremaining: 1m 42s\n",
      "600:\tlearn: 20970.3082045\ttest: 29958.4285339\tbest: 29958.4285339 (600)\ttotal: 23.6s\tremaining: 1m 34s\n",
      "800:\tlearn: 19498.7820905\ttest: 29001.2253005\tbest: 29001.2253005 (800)\ttotal: 31.3s\tremaining: 1m 25s\n",
      "1000:\tlearn: 18502.6537778\ttest: 28404.3515555\tbest: 28404.3515555 (1000)\ttotal: 39.2s\tremaining: 1m 18s\n",
      "1200:\tlearn: 17559.5554223\ttest: 28017.6967325\tbest: 28017.6967325 (1200)\ttotal: 47.4s\tremaining: 1m 11s\n",
      "1400:\tlearn: 16899.2906717\ttest: 27709.9012777\tbest: 27709.9012777 (1400)\ttotal: 55.8s\tremaining: 1m 3s\n",
      "1600:\tlearn: 16337.1865454\ttest: 27411.6861790\tbest: 27411.6861790 (1600)\ttotal: 1m 3s\tremaining: 55.9s\n",
      "1800:\tlearn: 15928.4105821\ttest: 27216.8864263\tbest: 27216.5751270 (1797)\ttotal: 1m 11s\tremaining: 47.9s\n",
      "2000:\tlearn: 15552.7901034\ttest: 27060.0954427\tbest: 27056.6874017 (1984)\ttotal: 1m 20s\tremaining: 40s\n",
      "2200:\tlearn: 15225.8553279\ttest: 26946.0396846\tbest: 26944.7736198 (2181)\ttotal: 1m 28s\tremaining: 32s\n",
      "2400:\tlearn: 14879.6045315\ttest: 26827.4230746\tbest: 26827.4230746 (2400)\ttotal: 1m 36s\tremaining: 24s\n",
      "2600:\tlearn: 14594.3117611\ttest: 26725.5933117\tbest: 26725.5933117 (2600)\ttotal: 1m 44s\tremaining: 16s\n",
      "2800:\tlearn: 14369.9714912\ttest: 26663.3039706\tbest: 26663.3039706 (2800)\ttotal: 1m 52s\tremaining: 7.98s\n",
      "2999:\tlearn: 14156.4351213\ttest: 26631.2698188\tbest: 26631.2698188 (2999)\ttotal: 2m\tremaining: 0us\n",
      "bestTest = 26631.26982\n",
      "bestIteration = 2999\n",
      "Fold 1 RMSE: 26631.27514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7af71e9345f463680007ee6fd89fcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict fold 1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2/5 ===\n",
      "0:\tlearn: 78044.8891189\ttest: 82139.2900550\tbest: 82139.2900550 (0)\ttotal: 43.3ms\tremaining: 2m 9s\n",
      "200:\tlearn: 31837.1201561\ttest: 35505.6845890\tbest: 35505.6845890 (200)\ttotal: 8.3s\tremaining: 1m 55s\n",
      "400:\tlearn: 23445.5581610\ttest: 29247.8302204\tbest: 29247.8302204 (400)\ttotal: 16.5s\tremaining: 1m 46s\n",
      "600:\tlearn: 20722.8546190\ttest: 27707.9461744\tbest: 27707.1553866 (599)\ttotal: 24.5s\tremaining: 1m 37s\n",
      "800:\tlearn: 19116.4721913\ttest: 26978.0567636\tbest: 26972.7693348 (799)\ttotal: 32.5s\tremaining: 1m 29s\n",
      "1000:\tlearn: 18163.1828241\ttest: 26582.2570550\tbest: 26582.2570550 (1000)\ttotal: 40.5s\tremaining: 1m 20s\n",
      "1200:\tlearn: 17611.3290561\ttest: 26414.1901590\tbest: 26412.5395873 (1177)\ttotal: 48.7s\tremaining: 1m 12s\n",
      "1400:\tlearn: 17230.7771790\ttest: 26229.9394011\tbest: 26225.1986320 (1386)\ttotal: 56.7s\tremaining: 1m 4s\n",
      "1600:\tlearn: 16908.9307099\ttest: 26107.6461586\tbest: 26107.6461586 (1600)\ttotal: 1m 4s\tremaining: 56.5s\n",
      "1800:\tlearn: 16560.9502738\ttest: 25959.9797201\tbest: 25959.9797201 (1800)\ttotal: 1m 12s\tremaining: 48.5s\n",
      "2000:\tlearn: 16240.8688073\ttest: 25795.7469660\tbest: 25794.8290369 (1997)\ttotal: 1m 20s\tremaining: 40.3s\n",
      "2200:\tlearn: 16015.6898414\ttest: 25701.3413306\tbest: 25700.7158538 (2197)\ttotal: 1m 29s\tremaining: 32.3s\n",
      "2400:\tlearn: 15837.5020585\ttest: 25629.7197351\tbest: 25629.7197351 (2400)\ttotal: 1m 36s\tremaining: 24.2s\n",
      "2600:\tlearn: 15663.0300118\ttest: 25560.6492082\tbest: 25557.1520869 (2583)\ttotal: 1m 44s\tremaining: 16.1s\n",
      "2800:\tlearn: 15488.5850676\ttest: 25521.0816450\tbest: 25521.0816450 (2800)\ttotal: 1m 52s\tremaining: 8.02s\n",
      "2999:\tlearn: 15350.3641008\ttest: 25482.4280988\tbest: 25480.7678171 (2988)\ttotal: 2m\tremaining: 0us\n",
      "bestTest = 25480.76782\n",
      "bestIteration = 2988\n",
      "Shrink model to first 2989 iterations.\n",
      "Fold 2 RMSE: 25480.79230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3a8f97f06d49cbb31a88efb872bda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict fold 2:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3/5 ===\n",
      "0:\tlearn: 80088.7203824\ttest: 73872.2789210\tbest: 73872.2789210 (0)\ttotal: 43.9ms\tremaining: 2m 11s\n",
      "200:\tlearn: 31624.1679871\ttest: 37258.2525079\tbest: 37258.2525079 (200)\ttotal: 7.94s\tremaining: 1m 50s\n",
      "400:\tlearn: 22941.9600553\ttest: 36448.2923004\tbest: 35933.0642990 (293)\ttotal: 15.7s\tremaining: 1m 41s\n",
      "bestTest = 35933.0643\n",
      "bestIteration = 293\n",
      "Shrink model to first 294 iterations.\n",
      "Fold 3 RMSE: 35933.06287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05192bd0a36c42e9a61840659159998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict fold 3:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4/5 ===\n",
      "0:\tlearn: 78915.8704514\ttest: 78754.7343795\tbest: 78754.7343795 (0)\ttotal: 39.8ms\tremaining: 1m 59s\n",
      "200:\tlearn: 31300.1009163\ttest: 36517.9711060\tbest: 36517.9711060 (200)\ttotal: 8.22s\tremaining: 1m 54s\n",
      "400:\tlearn: 22641.8654152\ttest: 31130.6381226\tbest: 31130.6381226 (400)\ttotal: 16.5s\tremaining: 1m 46s\n",
      "600:\tlearn: 19873.2744391\ttest: 29897.9556913\tbest: 29897.9556913 (600)\ttotal: 24.4s\tremaining: 1m 37s\n",
      "800:\tlearn: 18479.8564425\ttest: 29336.3980533\tbest: 29336.3980533 (800)\ttotal: 32.6s\tremaining: 1m 29s\n",
      "1000:\tlearn: 17554.9398769\ttest: 28980.4349609\tbest: 28978.0824800 (996)\ttotal: 40.9s\tremaining: 1m 21s\n",
      "1200:\tlearn: 16786.5462634\ttest: 28674.3306293\tbest: 28672.7338458 (1192)\ttotal: 49.2s\tremaining: 1m 13s\n",
      "1400:\tlearn: 16296.1075712\ttest: 28515.3755362\tbest: 28514.3109929 (1399)\ttotal: 57.5s\tremaining: 1m 5s\n",
      "1600:\tlearn: 15839.2795740\ttest: 28350.0773027\tbest: 28350.0773027 (1600)\ttotal: 1m 5s\tremaining: 57.4s\n",
      "1800:\tlearn: 15553.8426103\ttest: 28223.3956385\tbest: 28223.3956385 (1800)\ttotal: 1m 13s\tremaining: 49s\n",
      "2000:\tlearn: 15328.6987000\ttest: 28110.4949660\tbest: 28110.2324859 (1999)\ttotal: 1m 21s\tremaining: 40.9s\n",
      "2200:\tlearn: 15115.7966470\ttest: 28033.0568388\tbest: 28033.0568388 (2200)\ttotal: 1m 30s\tremaining: 32.7s\n",
      "2400:\tlearn: 14848.4137873\ttest: 27925.3968486\tbest: 27925.3044221 (2398)\ttotal: 1m 38s\tremaining: 24.5s\n",
      "2600:\tlearn: 14676.3397774\ttest: 27823.8587754\tbest: 27823.6641728 (2599)\ttotal: 1m 46s\tremaining: 16.3s\n",
      "2800:\tlearn: 14493.4214042\ttest: 27733.8019209\tbest: 27733.8019209 (2800)\ttotal: 1m 53s\tremaining: 8.1s\n",
      "2999:\tlearn: 14316.2917369\ttest: 27642.1079465\tbest: 27642.0023936 (2996)\ttotal: 2m 2s\tremaining: 0us\n",
      "bestTest = 27642.00239\n",
      "bestIteration = 2996\n",
      "Shrink model to first 2997 iterations.\n",
      "Fold 4 RMSE: 27641.97976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2792222dedb849028497eb113cd1c625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict fold 4:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 5/5 ===\n",
      "0:\tlearn: 80559.9233638\ttest: 71774.0220933\tbest: 71774.0220933 (0)\ttotal: 41.8ms\tremaining: 2m 5s\n",
      "200:\tlearn: 32653.3954785\ttest: 29168.1725887\tbest: 29168.1725887 (200)\ttotal: 8.37s\tremaining: 1m 56s\n",
      "400:\tlearn: 23449.5927260\ttest: 23688.1638648\tbest: 23688.1638648 (400)\ttotal: 16.6s\tremaining: 1m 47s\n",
      "600:\tlearn: 20199.5496383\ttest: 22482.5918459\tbest: 22482.5419320 (599)\ttotal: 24.6s\tremaining: 1m 38s\n",
      "800:\tlearn: 18290.4741672\ttest: 21856.3898960\tbest: 21855.3694127 (798)\ttotal: 32.7s\tremaining: 1m 29s\n",
      "1000:\tlearn: 17029.7009715\ttest: 21492.7961681\tbest: 21492.7961681 (1000)\ttotal: 40.9s\tremaining: 1m 21s\n",
      "1200:\tlearn: 16173.8422202\ttest: 21306.6673159\tbest: 21306.6673159 (1200)\ttotal: 49.4s\tremaining: 1m 14s\n",
      "1400:\tlearn: 15588.6362545\ttest: 21228.0738388\tbest: 21226.6841422 (1377)\ttotal: 57.6s\tremaining: 1m 5s\n",
      "1600:\tlearn: 15155.5664895\ttest: 21130.3718824\tbest: 21126.2622513 (1575)\ttotal: 1m 5s\tremaining: 57.5s\n",
      "1800:\tlearn: 14818.5437622\ttest: 21094.7887715\tbest: 21083.0101981 (1738)\ttotal: 1m 14s\tremaining: 49.3s\n",
      "2000:\tlearn: 14566.6884532\ttest: 21053.0778669\tbest: 21053.0778669 (2000)\ttotal: 1m 22s\tremaining: 41s\n",
      "2200:\tlearn: 14345.0666046\ttest: 21007.6547040\tbest: 21007.6547040 (2200)\ttotal: 1m 30s\tremaining: 32.7s\n",
      "2400:\tlearn: 14160.0246420\ttest: 20973.8070178\tbest: 20973.5401628 (2398)\ttotal: 1m 38s\tremaining: 24.5s\n",
      "2600:\tlearn: 13995.0438194\ttest: 20933.4479106\tbest: 20933.4479106 (2600)\ttotal: 1m 46s\tremaining: 16.3s\n",
      "2800:\tlearn: 13811.3925260\ttest: 20892.8711916\tbest: 20892.8711916 (2800)\ttotal: 1m 54s\tremaining: 8.12s\n",
      "2999:\tlearn: 13680.1470152\ttest: 20870.9527032\tbest: 20869.0068789 (2994)\ttotal: 2m 2s\tremaining: 0us\n",
      "bestTest = 20869.00688\n",
      "bestIteration = 2994\n",
      "Shrink model to first 2995 iterations.\n",
      "Fold 5 RMSE: 20868.98929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43841974c684f17803b32aaa4f7198f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict fold 5:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold_rmse: [26631.27513807109, 25480.792296902735, 35933.06287096188, 27641.97976360352, 20868.98928756146]\n",
      "mean_rmse: 27311.21987142014\n",
      "oof_rmse: 27746.25869547771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def rmse_func(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "N_SPLITS = 5\n",
    "N_ITER = 3000\n",
    "DEPTH = 8\n",
    "OD_WAIT = 300\n",
    "TASK_TYPE = \"GPU\"\n",
    "\n",
    "X = X_tr_feat\n",
    "y_arr = y\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(len(X))\n",
    "test_pred = np.zeros(len(X_te_feat))\n",
    "scores = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(tqdm(kf.split(X), total=N_SPLITS, desc=\"Folds\"), 1):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y_arr[tr_idx], y_arr[val_idx]\n",
    "\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_features)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_features)\n",
    "\n",
    "    params = dict(\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        iterations=N_ITER,\n",
    "        learning_rate=0.01,\n",
    "        depth=DEPTH,\n",
    "        l2_leaf_reg=3.0,\n",
    "        random_seed=42 + fold,\n",
    "        verbose=200,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=OD_WAIT,\n",
    "        task_type=TASK_TYPE,\n",
    "    )\n",
    "\n",
    "    if TASK_TYPE == \"GPU\":\n",
    "        params[\"devices\"] = \"0\"\n",
    "\n",
    "    print(f\"\\n=== Fold {fold}/{N_SPLITS} ===\")\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "    oof[val_idx] = val_pred\n",
    "    rmse = rmse_func(y_val, val_pred)\n",
    "    scores.append(rmse)\n",
    "    print(f\"Fold {fold} RMSE: {rmse:.5f}\")\n",
    "\n",
    "    bs = 1024\n",
    "    fold_test = np.zeros(len(X_te_feat))\n",
    "    for s in tqdm(range(0, len(X_te_feat), bs), leave=False, desc=f\"Predict fold {fold}\"):\n",
    "        e = s + bs\n",
    "        fold_test[s:e] = model.predict(X_te_feat.iloc[s:e])\n",
    "    test_pred += fold_test / N_SPLITS\n",
    "\n",
    "oof_rmse = rmse_func(y_arr, oof)\n",
    "print(\"\\nfold_rmse:\", scores)\n",
    "print(\"mean_rmse:\", np.mean(scores))\n",
    "print(\"oof_rmse:\", oof_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f985a72-c57c-48b3-818b-ffdbbddc0e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>121612.924839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>160658.343975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>175427.156194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>183807.068378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>200770.568554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  121612.924839\n",
       "1  1462  160658.343975\n",
       "2  1463  175427.156194\n",
       "3  1464  183807.068378\n",
       "4  1465  200770.568554"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# предполагаем, что есть:\n",
    "# - test (оригинальный тестовый df)\n",
    "# - test_pred (предсказания из k-fold)\n",
    "# - target_col (имя таргета, как в train)\n",
    "\n",
    "id_col = \"id\"  # или \"ID\", или другое\n",
    "for c in [\"id\", \"ID\", \"Id\"]:\n",
    "    if c in test.columns:\n",
    "        id_col = c\n",
    "        break\n",
    "\n",
    "if id_col is not None:\n",
    "    sub = pd.DataFrame({\n",
    "        id_col: test[id_col].values,\n",
    "        target_col: test_pred\n",
    "    })\n",
    "else:\n",
    "    sub = pd.DataFrame({\n",
    "        \"id\": np.arange(len(test_pred)),\n",
    "        target_col: test_pred\n",
    "    })\n",
    "\n",
    "sub.to_csv(\"submission_catboost_kfold_autofeat_gpu.csv\", index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c4a56ea-dc30-4dbb-8658-b4e6ddb46c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) (1459, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  Street  Utilities  OverallQual  \\\n",
       "0   1          60         65.0     8450       1          0            7   \n",
       "1   2          20         80.0     9600       1          0            6   \n",
       "2   3          60         68.0    11250       1          0            7   \n",
       "3   4          70         60.0     9550       1          0            7   \n",
       "4   5          60         84.0    14260       1          0            8   \n",
       "\n",
       "   OverallCond  YearBuilt  YearRemodAdd  ...  GarageFinish  GarageQual  \\\n",
       "0            5       2003          2003  ...             2           5   \n",
       "1            8       1976          1976  ...             2           5   \n",
       "2            5       2001          2002  ...             2           5   \n",
       "3            5       1915          1970  ...             3           5   \n",
       "4            5       2000          2000  ...             2           5   \n",
       "\n",
       "   GarageCond  PavedDrive  PoolQC  Fence  MiscFeature  SaleType  \\\n",
       "0           5           2       0      0            0         8   \n",
       "1           5           2       0      0            0         8   \n",
       "2           5           2       0      0            0         8   \n",
       "3           5           2       0      0            0         8   \n",
       "4           5           2       0      0            0         8   \n",
       "\n",
       "   SaleCondition  SalePrice  \n",
       "0              4     208500  \n",
       "1              4     181500  \n",
       "2              4     223500  \n",
       "3              0     140000  \n",
       "4              4     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ag = X_tr_feat.copy()\n",
    "train_ag[target_col] = y\n",
    "\n",
    "test_ag = X_te_feat.copy()\n",
    "\n",
    "print(train_ag.shape, test_ag.shape)\n",
    "train_ag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6834c56-3214-46b1-aa82-dc3cf66f27df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularPredictor импортирован.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"TabularPredictor импортирован.\")\n",
    "except ImportError:\n",
    "    print(\"autogluon.tabular не найден, ставим...\")\n",
    "    !{sys.executable} -m pip install -q autogluon.tabular==1.4.0\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"autogluon.tabular установлен и импортирован.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8fd937-6cab-4572-ab54-de24f39307e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251118_214104\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #40~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 16 10:53:04 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       379.88 GB / 503.54 GB (75.4%)\n",
      "Disk Space Avail:   128.69 GB / 130.00 GB (99.0%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/workspace/AutogluonModels/ag-20251118_214104\"\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 80\n",
      "Label Column:       SalePrice\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    388953.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.65 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 37 | ['Id', 'MSSubClass', 'LotArea', 'Street', 'Utilities', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.2s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1168, Val Rows: 292\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 1799.81s of the 1799.81s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBM ... Training model for up to 1799.72s of the 1799.71s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: RandomForestMSE ... Training model for up to 1799.63s of the 1799.63s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1\n",
      "\t-33156.0814\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 1798.99s of the 1798.99s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-31554.1148\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 1763.59s of the 1763.59s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1\n",
      "\t-32571.9583\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 1763.14s of the 1763.14s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1, mem=0.0/379.9 GB\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.4.0`. \n",
      "Fitting model: XGBoost ... Training model for up to 1763.07s of the 1763.07s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1\n",
      "\tWarning: Exception caused XGBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 1762.94s of the 1762.94s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1, mem=0.0/380.0 GB\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1762.85s of the 1762.85s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1762.75s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.64, 'ExtraTreesMSE': 0.36}\n",
      "\t-31077.5602\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 37.27s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5068.6 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/AutogluonModels/ag-20251118_214104\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=target_col,\n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"rmse\"\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    time_limit=1800,  # можно 600/900/3600 по ситуации\n",
    "    presets=\"medium_quality_faster_train\",\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58d0f23b-2eed-47c0-a80f-d855dd4c67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n"
     ]
    }
   ],
   "source": [
    "print('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "238261e6-55f7-4e69-88f2-64ef6b8cd228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid_col = \"id\"  # или \"ID\", или другое имя, если нужно\\n\\nag_pred = predictor.predict(test_ag)\\n\\nsub_ag = test[[id_col]].copy()\\nsub_ag[target_col] = ag_pred\\n\\nsub_ag.to_csv(\"submission_autogluon_autofeat_1.csv\", index=False)\\nsub_ag.head()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' если нужна модель тяжелее хотим presets=\"best_quality\" '''\n",
    "\n",
    "'''лидерборд'''\n",
    "'''\n",
    "leaderboard = predictor.leaderboard(train_ag, silent=True)\n",
    "leaderboard\n",
    "'''\n",
    "\n",
    "'''предсказания и сабмит'''\n",
    "\n",
    "'''\n",
    "id_col = \"id\"  # или \"ID\", или другое имя, если нужно\n",
    "\n",
    "ag_pred = predictor.predict(test_ag)\n",
    "\n",
    "sub_ag = test[[id_col]].copy()\n",
    "sub_ag[target_col] = ag_pred\n",
    "\n",
    "sub_ag.to_csv(\"submission_autogluon_autofeat_1.csv\", index=False)\n",
    "sub_ag.head()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f581bc8-fb01-415f-919b-50548d9fed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251118_214711\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor_cat не найден → создаём минимальный CatBoost-предиктор…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor_cat создан.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-21233.529476</td>\n",
       "      <td>-32260.18986</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>12.528390</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>12.528390</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-21233.529476</td>\n",
       "      <td>-32260.18986</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.013146</td>\n",
       "      <td>0.013669</td>\n",
       "      <td>12.529773</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model    score_test    score_val              eval_metric  \\\n",
       "0             CatBoost -21233.529476 -32260.18986  root_mean_squared_error   \n",
       "1  WeightedEnsemble_L2 -21233.529476 -32260.18986  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0        0.011924       0.013442  12.528390                 0.011924   \n",
       "1        0.013146       0.013669  12.529773                 0.001221   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.013442          12.528390            1       True   \n",
       "1                0.000227           0.001383            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 1. Проверяем, импортирован ли AutoGluon\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "except ImportError:\n",
    "    print(\"autogluon.tabular не найден, ставим...\")\n",
    "    !{sys.executable} -m pip install -q autogluon.tabular==1.4.0\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# 2. Проверяем, существует ли predictor_cat\n",
    "if \"predictor_cat\" not in globals():\n",
    "    print(\"predictor_cat не найден → создаём минимальный CatBoost-предиктор…\")\n",
    "\n",
    "    # проверяем, что train_ag и target_col существуют\n",
    "    assert \"train_ag\" in globals(), \"train_ag не найден\"\n",
    "    assert \"target_col\" in globals(), \"target_col не найден\"\n",
    "\n",
    "    predictor_cat = TabularPredictor(\n",
    "        label=target_col,\n",
    "        problem_type=\"regression\",\n",
    "        eval_metric=\"rmse\",\n",
    "    ).fit(\n",
    "        train_data=train_ag,\n",
    "        hyperparameters={\n",
    "            \"CAT\": {\n",
    "                \"iterations\": 500,   # небольшое число, чтобы не ждать\n",
    "                \"depth\": 6,\n",
    "            }\n",
    "        },\n",
    "        ag_args_fit={\"num_gpus\": 1},\n",
    "        verbosity=1,\n",
    "    )\n",
    "    print(\"predictor_cat создан.\")\n",
    "else:\n",
    "    print(\"predictor_cat уже существует.\")\n",
    "\n",
    "# 3. Теперь можно безопасно вызвать leaderboard\n",
    "leaderboard_cat = predictor_cat.leaderboard(train_ag, silent=True)\n",
    "leaderboard_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1495a40d-3323-4e27-914e-8bf99072d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_cat = predictor_cat.leaderboard(train_ag, silent=True)\n",
    "leaderboard_cat\n",
    "\n",
    "ag_train_pred = predictor_cat.predict(train_ag)\n",
    "ag_test_pred = predictor_cat.predict(test_ag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507448a-0062-418a-9d98-d342e771afe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63870e94-daa9-4140-9806-124af99356d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ca4cb-da39-49c6-a6d7-600628cfed2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a35670-7304-44ba-b61d-f1082579fb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b5fe4-ef7a-4287-869e-1cd06b159848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2eecb38-7454-43ae-a2eb-d7dcbf7fbef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251118_214749\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #40~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 16 10:53:04 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       379.88 GB / 503.54 GB (75.4%)\n",
      "Disk Space Avail:   128.63 GB / 130.00 GB (98.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/workspace/AutogluonModels/ag-20251118_214749\"\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 80\n",
      "Label Column:       SalePrice\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    388999.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.65 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 37 | ['Id', 'MSSubClass', 'LotArea', 'Street', 'Utilities', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.2s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1168, Val Rows: 292\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'CAT': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost ... Training model for up to 1799.82s of the 1799.82s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-31554.1148\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1763.88s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t-31554.1148\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 23599.8 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/AutogluonModels/ag-20251118_214749\")\n"
     ]
    }
   ],
   "source": [
    "\"глюон тока с катбустом\"\n",
    "\n",
    "predictor_cat = TabularPredictor(\n",
    "    label=target_col,\n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"rmse\",\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    time_limit=1800,  # можно уменьшить/увеличить\n",
    "    hyperparameters={\n",
    "        'CAT': {}   # включаем только CatBoost-модели\n",
    "    },\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9540c4-7653-4e12-9dd3-207cba0a7919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c369a2-3457-433d-9c43-13d8dd131c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b17a14-2625-480c-a659-141115fe2543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51cabcd-b524-4bd2-bbd9-a0af36f98336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b7795c5-b3f6-4eec-b870-fa1e9b3c96e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>120742.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>160395.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>173950.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>184825.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>200828.468750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  120742.289062\n",
       "1  1462  160395.984375\n",
       "2  1463  173950.078125\n",
       "3  1464  184825.453125\n",
       "4  1465  200828.468750"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_col = \"Id\"  # или \"ID\", или другое имя, если нужно\n",
    "\n",
    "ag_pred = predictor.predict(test_ag)\n",
    "\n",
    "sub_ag = test[[id_col]].copy()\n",
    "sub_ag[target_col] = ag_pred\n",
    "\n",
    "sub_ag.to_csv(\"submission_autogluon_autofeat_id_target.csv\", index=False)\n",
    "sub_ag.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8b4a3-9abd-47d7-9abc-2a4453c5cc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9fab672-7faf-4546-a55e-6aedd0cc681a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120742.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160395.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173950.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184825.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200828.468750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SalePrice\n",
       "0  120742.289062\n",
       "1  160395.984375\n",
       "2  173950.078125\n",
       "3  184825.453125\n",
       "4  200828.468750"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_pred = predictor.predict(test_ag)\n",
    "\n",
    "sub_ag = pd.DataFrame({target_col: ag_pred})\n",
    "sub_ag.to_csv(\"submission_autogluon_autofeat_only_id.csv\", index=False)\n",
    "sub_ag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "533b0553-b752-4fdb-aa29-d3ead03e3038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "train_ag = X_tr_feat.copy()\n",
    "train_ag[target_col] = y\n",
    "test_ag = X_te_feat.copy()\n",
    "\n",
    "train_ag.shape, test_ag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36dea177-2150-4f8e-aa6e-36f6025b0de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251118_215042\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #40~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 16 10:53:04 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       379.90 GB / 503.54 GB (75.4%)\n",
      "Disk Space Avail:   128.63 GB / 130.00 GB (98.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/workspace/AutogluonModels/ag-20251118_215042\"\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 80\n",
      "Label Column:       SalePrice\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    389032.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.65 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 37 | ['Id', 'MSSubClass', 'LotArea', 'Street', 'Utilities', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.2s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1168, Val Rows: 292\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'CAT': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost ... Training model for up to 1799.81s of the 1799.81s of remaining time.\n",
      "\tFitting with cpus=8, gpus=1\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-31554.1148\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1763.68s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t-31554.1148\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 22141.9 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/AutogluonModels/ag-20251118_215042\")\n"
     ]
    }
   ],
   "source": [
    "predictor_cat = TabularPredictor(\n",
    "    label=target_col,\n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"rmse\",\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    time_limit=1800,  # можно уменьшить/увеличить\n",
    "    hyperparameters={\n",
    "        'CAT': {}   # включаем только CatBoost-модели\n",
    "    },\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39c45a5e-dc81-4beb-8a5c-0d3b4aa594ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-19612.661973</td>\n",
       "      <td>-31554.114752</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.01482</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>36.111448</td>\n",
       "      <td>0.014820</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>36.111448</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-19612.661973</td>\n",
       "      <td>-31554.114752</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.01607</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>36.112713</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model    score_test     score_val              eval_metric  \\\n",
       "0             CatBoost -19612.661973 -31554.114752  root_mean_squared_error   \n",
       "1  WeightedEnsemble_L2 -19612.661973 -31554.114752  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0         0.01482       0.012974  36.111448                 0.014820   \n",
       "1         0.01607       0.013188  36.112713                 0.001251   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.012974          36.111448            1       True   \n",
       "1                0.000214           0.001265            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_cat = predictor_cat.leaderboard(train_ag, silent=True)\n",
    "leaderboard_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1bc2e50-56e8-45b2-9096-caeeba8bf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_train_pred = predictor_cat.predict(train_ag)\n",
    "ag_test_pred = predictor_cat.predict(test_ag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea09f4-7d0d-415f-b2c9-d6807b699d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''blend'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1dd08de-e792-4274-9bec-368a46561e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1803559\ttotal: 16.7ms\tremaining: 33.3s\n",
      "100:\tlearn: 0.9898654\ttotal: 784ms\tremaining: 14.7s\n",
      "200:\tlearn: 0.9848862\ttotal: 1.65s\tremaining: 14.8s\n",
      "300:\tlearn: 0.9827911\ttotal: 2.56s\tremaining: 14.4s\n",
      "400:\tlearn: 0.9804082\ttotal: 3.36s\tremaining: 13.4s\n",
      "500:\tlearn: 0.9781054\ttotal: 4.17s\tremaining: 12.5s\n",
      "600:\tlearn: 0.9761623\ttotal: 4.79s\tremaining: 11.2s\n",
      "700:\tlearn: 0.9744053\ttotal: 5.1s\tremaining: 9.45s\n",
      "800:\tlearn: 0.9728192\ttotal: 5.49s\tremaining: 8.22s\n",
      "900:\tlearn: 0.9713416\ttotal: 5.91s\tremaining: 7.21s\n",
      "1000:\tlearn: 0.9699321\ttotal: 6.33s\tremaining: 6.32s\n",
      "1100:\tlearn: 0.9686531\ttotal: 6.74s\tremaining: 5.5s\n",
      "1200:\tlearn: 0.9674257\ttotal: 7.16s\tremaining: 4.76s\n",
      "1300:\tlearn: 0.9662867\ttotal: 7.59s\tremaining: 4.08s\n",
      "1400:\tlearn: 0.9651149\ttotal: 8.02s\tremaining: 3.43s\n",
      "1500:\tlearn: 0.9640560\ttotal: 8.43s\tremaining: 2.8s\n",
      "1600:\tlearn: 0.9631643\ttotal: 8.83s\tremaining: 2.2s\n",
      "1700:\tlearn: 0.9622188\ttotal: 9.25s\tremaining: 1.63s\n",
      "1800:\tlearn: 0.9613573\ttotal: 9.67s\tremaining: 1.07s\n",
      "1900:\tlearn: 0.9605074\ttotal: 10.1s\tremaining: 525ms\n",
      "1999:\tlearn: 0.9596072\ttotal: 10.5s\tremaining: 0us\n",
      "blend RMSE: 0.959607192599873\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "\n",
    "Z_train = np.vstack([\n",
    "    oof,                    # OOF из твоего KFold CatBoost\n",
    "    ag_train_pred.values    # предсказания AutoGluon на train\n",
    "]).T\n",
    "\n",
    "Z_test = np.vstack([\n",
    "    test_pred,              # предсказания твоего KFold CatBoost на test\n",
    "    ag_test_pred.values     # предсказания AutoGluon на test\n",
    "]).T\n",
    "\n",
    "meta_model = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=777,\n",
    "    verbose=100,\n",
    "    task_type=\"CPU\",   # можно сменить на \"GPU\", devices=\"0\"\n",
    ")\n",
    "\n",
    "meta_model.fit(Z_train, y)\n",
    "\n",
    "blend_oof = meta_model.predict(Z_train)\n",
    "blend_rmse = rmse_func(y, blend_oof)\n",
    "print(\"blend RMSE:\", blend_rmse)\n",
    "\n",
    "blend_test = meta_model.predict(Z_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03d34f23-39f5-4e58-b694-3c26eef16545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если в test есть id-колонка\n",
    "id_col = \"id\"  # или своё имя\n",
    "\n",
    "sub_blend = test[[id_col]].copy()\n",
    "sub_blend[target_col] = blend_test\n",
    "sub_blend.to_csv(\"submission_blend_catboost_meta.csv\", index=False)\n",
    "sub_blend.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b6fb3-0313-4939-b335-3108cc9f3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''далее улучшение всего вышеперечисленного (потяжелее модели) + маленько иного'''\n",
    "'''почти с нуля все'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaf606f4-60ef-481e-a6ca-556e99937c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1459, 80))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\".\")\n",
    "\n",
    "TRAIN_PATH = DATA_DIR / \"train_home.csv\"   # или train.csv\n",
    "TEST_PATH  = DATA_DIR / \"test_home.csv\"    # или test.csv\n",
    "SEP = \",\"                             # \"\\t\" для tsv, \",\" для csv\n",
    "\n",
    "TARGET_COL = \"SalePrice\"            # имя таргета\n",
    "ID_COL = \"Id\"                         # имя id-колонки в test (или None, если её нет)\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)    # pd.read_csv(TEST_PATH,  sep=SEP)\n",
    "\n",
    "feature_cols = [c for c in train.columns if c != TARGET_COL and c in test.columns]\n",
    "\n",
    "X_raw = train[feature_cols].copy()\n",
    "y = train[TARGET_COL].values\n",
    "X_test_raw = test[feature_cols].copy()\n",
    "\n",
    "X_raw.shape, X_test_raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c16939ac-090a-4762-99ab-1fbe9974bd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    388869.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.2s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "WARNING: Int features without null values at train time contain null values at inference time! Imputing nulls to 0. To avoid this, pass the features as floats during fit!\n",
      "WARNING: Int features with nulls: ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1459, 80))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg = AutoMLPipelineFeatureGenerator(\n",
    "    enable_numeric_features=True,\n",
    "    enable_categorical_features=True,\n",
    "    enable_datetime_features=True,\n",
    "    enable_text_special_features=True,\n",
    "    enable_text_ngram_features=True,\n",
    "    enable_raw_text_features=False,\n",
    ")\n",
    "\n",
    "X_tr_feat = fg.fit_transform(X=X_raw, y=y)\n",
    "X_te_feat = fg.transform(X_test_raw)\n",
    "\n",
    "X_tr_feat.shape, X_te_feat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ea82a69-46d6-4927-a360-8a5b3fb434f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ag = X_tr_feat.copy()\n",
    "train_ag[TARGET_COL] = y\n",
    "\n",
    "test_ag = X_te_feat.copy()\n",
    "\n",
    "train_ag.shape, test_ag.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea98943-8953-47b2-b26a-f944eb5d27c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cff032f-3bb0-4033-9c40-95d5a2385e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hyperparams_base = {\\n    \"GBM\": [\\n        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM\"}},\\n        {\"extra_trees\": True,  \"ag_args\": {\"name_suffix\": \"GBM_XT\"}},\\n    ],\\n    \"CAT\": {\\n        \"iterations\": 4000,\\n        \"depth\": 8,\\n        \"learning_rate\": 0.01,\\n    },\\n    \"XGB\": {},\\n    \"NN_TORCH\": {},\\n}\\n\\npredictor = TabularPredictor(\\n    label=TARGET_COL,\\n    problem_type=\"regression\",\\n    eval_metric=\"rmse\",\\n).fit(\\n    train_data=train_ag,\\n    time_limit=1800,\\n    presets=\"medium_quality_faster_train\",\\n    hyperparameters=hyperparams_base,\\n    ag_args_fit={\"num_gpus\": 1},\\n)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''hyperparams_base = {\n",
    "    \"GBM\": [\n",
    "        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM\"}},\n",
    "        {\"extra_trees\": True,  \"ag_args\": {\"name_suffix\": \"GBM_XT\"}},\n",
    "    ],\n",
    "    \"CAT\": {\n",
    "        \"iterations\": 4000,\n",
    "        \"depth\": 8,\n",
    "        \"learning_rate\": 0.01,\n",
    "    },\n",
    "    \"XGB\": {},\n",
    "    \"NN_TORCH\": {},\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"rmse\",\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    time_limit=1800,\n",
    "    presets=\"medium_quality_faster_train\",\n",
    "    hyperparameters=hyperparams_base,\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a93ef89-36b3-4d09-89ee-d45d97d8acf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 3 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_extra ... Training model for up to 1200.00s of the 1200.00s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_extra to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_XT_extra ... Training model for up to 1199.56s of the 1199.56s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_XT_extra to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoost_2 ... Training model for up to 1199.11s of the 1199.11s of remaining time.\n",
      "\tFitting with cpus=62, gpus=1, mem=2.5/427.6 GB\n",
      "\tTraining CatBoost_2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-0.9797\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.82s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_2_L2 ... Training model for up to 360.00s of the 1168.20s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_2': 1.0}\n",
      "\t-0.9797\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_215837\")\n"
     ]
    }
   ],
   "source": [
    "hyperparams_extra = {\n",
    "    \"CAT\": {\n",
    "        \"iterations\": 4000,\n",
    "        \"depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "    },\n",
    "    \"GBM\": [\n",
    "        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM_extra\"}},\n",
    "        {\"extra_trees\": True,  \"ag_args\": {\"name_suffix\": \"GBM_XT_extra\"}},\n",
    "    ],\n",
    "}\n",
    "\n",
    "predictor = predictor.fit_extra(\n",
    "    hyperparameters=hyperparams_extra,\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    "    time_limit=1200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f1f1677-a8d2-4509-9aef-108f8abdb832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.978940</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.148261</td>\n",
       "      <td>0.051061</td>\n",
       "      <td>63.012222</td>\n",
       "      <td>0.148261</td>\n",
       "      <td>0.051061</td>\n",
       "      <td>63.012222</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.978940</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.151422</td>\n",
       "      <td>0.051380</td>\n",
       "      <td>63.014216</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_2</td>\n",
       "      <td>-1.003683</td>\n",
       "      <td>-0.979668</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.102016</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>30.824694</td>\n",
       "      <td>0.102016</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>30.824694</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_2_L2</td>\n",
       "      <td>-1.003683</td>\n",
       "      <td>-0.979668</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>0.051771</td>\n",
       "      <td>30.826800</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  score_val              eval_metric  \\\n",
       "0               CatBoost   -0.999949  -0.978940  root_mean_squared_error   \n",
       "1    WeightedEnsemble_L2   -0.999949  -0.978940  root_mean_squared_error   \n",
       "2             CatBoost_2   -1.003683  -0.979668  root_mean_squared_error   \n",
       "3  WeightedEnsemble_2_L2   -1.003683  -0.979668  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0        0.148261       0.051061  63.012222                 0.148261   \n",
       "1        0.151422       0.051380  63.014216                 0.003161   \n",
       "2        0.102016       0.051478  30.824694                 0.102016   \n",
       "3        0.104718       0.051771  30.826800                 0.002702   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.051061          63.012222            1       True   \n",
       "1                0.000319           0.001994            2       True   \n",
       "2                0.051478          30.824694            1       True   \n",
       "3                0.000293           0.002107            2       True   \n",
       "\n",
       "   fit_order  \n",
       "0          1  \n",
       "1          2  \n",
       "2          3  \n",
       "3          4  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = predictor.leaderboard(train_ag, silent=True)\n",
    "lb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "221e816c-4198-4ecf-b1b7-9fe596ff0a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 916 features using 5000 rows with 5 shuffle sets...\n",
      "\t1571.19s\t= Expected runtime (314.24s per shuffle set)\n",
      "\t133.35s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>1.067495e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.196789</td>\n",
       "      <td>0.183273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.095356</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>1.643011e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.107314</td>\n",
       "      <td>0.083398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>2.648099e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.006469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinates</th>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>1.486646e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>5.540305e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.москва</th>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>4.270179e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_income_1000m</th>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.655252e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.троицк</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>5.234521e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.зеленоград</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>3.444998e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_income_300m</th>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>4.294521e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pregnancy_websites_300m</th>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.991233e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children_goods_for_walks_and_travel_300m</th>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>3.240168e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.боровское</th>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>8.354882e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.word_count</th>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>2.359398e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime_1000m</th>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>2.717358e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby_food_1000m</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>7.664168e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>-0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.symbol_count..</th>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>4.478139e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.арбат</th>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>4.707519e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>-0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.балашиха</th>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>6.852329e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bars_1000m</th>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>8.304146e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>-0.000042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          importance    stddev       p_value  \\\n",
       "category                                    0.190031  0.003282  1.067495e-08   \n",
       "name                                        0.095356  0.005808  1.643011e-06   \n",
       "id                                          0.011836  0.002606  2.648099e-04   \n",
       "coordinates                                 0.008139  0.001545  1.486646e-04   \n",
       "address                                     0.005589  0.001491  5.540305e-04   \n",
       "__nlp__.москва                              0.000860  0.000214  4.270179e-04   \n",
       "mean_income_1000m                           0.000773  0.000084  1.655252e-05   \n",
       "__nlp__.троицк                              0.000737  0.000363  5.234521e-03   \n",
       "__nlp__.зеленоград                          0.000690  0.000302  3.444998e-03   \n",
       "mean_income_300m                            0.000645  0.000161  4.294521e-04   \n",
       "pregnancy_websites_300m                     0.000611  0.000125  1.991233e-04   \n",
       "children_goods_for_walks_and_travel_300m    0.000597  0.000139  3.240168e-04   \n",
       "__nlp__.боровское                           0.000567  0.000169  8.354882e-04   \n",
       "address.word_count                          0.000501  0.000197  2.359398e-03   \n",
       "anime_1000m                                 0.000395  0.000162  2.717358e-03   \n",
       "baby_food_1000m                             0.000354  0.000195  7.664168e-03   \n",
       "address.symbol_count..                      0.000351  0.000165  4.478139e-03   \n",
       "__nlp__.арбат                               0.000297  0.000303  4.707519e-02   \n",
       "__nlp__.балашиха                            0.000279  0.000149  6.852329e-03   \n",
       "bars_1000m                                  0.000261  0.000147  8.304146e-03   \n",
       "\n",
       "                                          n  p99_high   p99_low  \n",
       "category                                  5  0.196789  0.183273  \n",
       "name                                      5  0.107314  0.083398  \n",
       "id                                        5  0.017202  0.006469  \n",
       "coordinates                               5  0.011320  0.004957  \n",
       "address                                   5  0.008659  0.002519  \n",
       "__nlp__.москва                            5  0.001301  0.000418  \n",
       "mean_income_1000m                         5  0.000946  0.000600  \n",
       "__nlp__.троицк                            5  0.001484 -0.000010  \n",
       "__nlp__.зеленоград                        5  0.001311  0.000069  \n",
       "mean_income_300m                          5  0.000977  0.000314  \n",
       "pregnancy_websites_300m                   5  0.000868  0.000353  \n",
       "children_goods_for_walks_and_travel_300m  5  0.000882  0.000312  \n",
       "__nlp__.боровское                         5  0.000914  0.000220  \n",
       "address.word_count                        5  0.000907  0.000096  \n",
       "anime_1000m                               5  0.000728  0.000063  \n",
       "baby_food_1000m                           5  0.000755 -0.000047  \n",
       "address.symbol_count..                    5  0.000692  0.000011  \n",
       "__nlp__.арбат                             5  0.000922 -0.000328  \n",
       "__nlp__.балашиха                          5  0.000585 -0.000027  \n",
       "bars_1000m                                5  0.000564 -0.000042  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = predictor.feature_importance(train_ag)\n",
    "fi.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfacfb9c-b9fd-48c4-bbfb-1eabf772afe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = fi[fi[\"importance\"] > 0].index.tolist()\n",
    "len(important_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04ead45c-3b57-4a1a-963b-d57d9ff83bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41105, 727), (9276, 726))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ag_imp = train_ag[important_features + [TARGET_COL]].copy()\n",
    "test_ag_imp  = test_ag[important_features].copy()\n",
    "\n",
    "train_ag_imp.shape, test_ag_imp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67760612-3089-40ee-b970-953f0aff6507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_220420\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2\n",
      "CPU Count:          62\n",
      "Memory Avail:       423.48 GB / 503.46 GB (84.1%)\n",
      "Disk Space Avail:   126.92 GB / 130.00 GB (97.6%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Beginning AutoGluon training ... Time limit = 1200s\n",
      "AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_220420\"\n",
      "Train Data Rows:    41105\n",
      "Train Data Columns: 726\n",
      "Label Column:       target\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    433659.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 121.33 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 411 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   4 | ['category', 'name', 'coordinates', 'address']\n",
      "\t\t('float', [])    : 273 | ['mean_income_1000m', 'mean_income_300m', 'pregnancy_websites_300m', 'children_goods_for_walks_and_travel_300m', 'anime_1000m', ...]\n",
      "\t\t('int', [])      : 449 | ['id', '__nlp__.москва', '__nlp__.троицк', '__nlp__.зеленоград', '__nlp__.боровское', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :   4 | ['category', 'name', 'coordinates', 'address']\n",
      "\t\t('float', [])     : 273 | ['mean_income_1000m', 'mean_income_300m', 'pregnancy_websites_300m', 'children_goods_for_walks_and_travel_300m', 'anime_1000m', ...]\n",
      "\t\t('int', [])       :  38 | ['id', '__nlp__.москва', 'address.word_count', 'address.symbol_count..', '__nlp__.мытищи', ...]\n",
      "\t\t('int', ['bool']) : 411 | ['__nlp__.троицк', '__nlp__.зеленоград', '__nlp__.боровское', '__nlp__.арбат', '__nlp__.балашиха', ...]\n",
      "\t4.3s = Fit runtime\n",
      "\t726 features in original data used to generate 726 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 105.22 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.43s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.060819851599562096, Train Rows: 38605, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'CAT': [{'iterations': 4000, 'depth': 7, 'learning_rate': 0.01}],\n",
      "\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM_slim'}}],\n",
      "}\n",
      "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_slim ... Training model for up to 1195.57s of the 1195.57s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_slim to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoost ... Training model for up to 1195.21s of the 1195.21s of remaining time.\n",
      "\tFitting with cpus=62, gpus=1, mem=1.5/423.3 GB\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-0.9622\t = Validation score   (-mean_squared_error)\n",
      "\t50.96s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1144.12s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t-0.9622\t = Validation score   (-mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 56.06s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 52511.8 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_220420\")\n"
     ]
    }
   ],
   "source": [
    "hyperparams_slim = {\n",
    "    \"CAT\": {\n",
    "        \"iterations\": 4000,\n",
    "        \"depth\": 7,\n",
    "        \"learning_rate\": 0.01,\n",
    "    },\n",
    "    \"GBM\": [\n",
    "        {\"extra_trees\": False, \"ag_args\": {\"name_suffix\": \"GBM_slim\"}},\n",
    "    ],\n",
    "}\n",
    "\n",
    "predictor_slim = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"mse\",\n",
    ").fit(\n",
    "    train_data=train_ag_imp,\n",
    "    time_limit=1200,\n",
    "    presets=\"medium_quality_faster_train\",\n",
    "    hyperparameters=hyperparams_slim,\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97d4aea5-244b-4258-b02b-b7c3cce53caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_base = predictor.predict(test_ag)\n",
    "test_pred_slim = predictor_slim.predict(test_ag_imp)\n",
    "\n",
    "test_pred_blend = 0.5 * test_pred_base.values + 0.5 * test_pred_slim.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5142bd8-96c3-4a8d-b0e7-e5b9f7d952c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21472</td>\n",
       "      <td>3.402225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9837</td>\n",
       "      <td>3.115150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41791</td>\n",
       "      <td>3.925786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18441</td>\n",
       "      <td>3.096871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49348</td>\n",
       "      <td>2.726351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target\n",
       "0  21472  3.402225\n",
       "1   9837  3.115150\n",
       "2  41791  3.925786\n",
       "3  18441  3.096871\n",
       "4  49348  2.726351"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ID_COL is not None and ID_COL in test.columns:\n",
    "    sub_base = test[[ID_COL]].copy()\n",
    "    sub_slim = test[[ID_COL]].copy()\n",
    "    sub_blend = test[[ID_COL]].copy()\n",
    "else:\n",
    "    sub_base = pd.DataFrame()\n",
    "    sub_slim = pd.DataFrame()\n",
    "    sub_blend = pd.DataFrame()\n",
    "\n",
    "sub_base[TARGET_COL] = test_pred_base\n",
    "sub_slim[TARGET_COL] = test_pred_slim\n",
    "sub_blend[TARGET_COL] = test_pred_blend\n",
    "\n",
    "sub_base.to_csv(\"submission_ag_base.csv\", index=False)\n",
    "sub_slim.to_csv(\"submission_ag_slim.csv\", index=False)\n",
    "sub_blend.to_csv(\"submission_ag_blend.csv\", index=False)\n",
    "\n",
    "sub_blend.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abd345-cf01-430e-9640-710f5f40781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''сейчас попробую взять еще толще модели, а то скор сильно не меняется'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b1cdcba-a25a-48db-9ba8-30d0d9ad965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_hps = {\n",
    "    \"GBM\": [\n",
    "        {\n",
    "            \"extra_trees\": False,\n",
    "            \"ag_args\": {\"name_suffix\": \"GBM_main\"},\n",
    "            \"num_leaves\": 64,\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"bagging_fraction\": 0.9,\n",
    "            \"bagging_freq\": 1,\n",
    "        },\n",
    "        {\n",
    "            \"extra_trees\": True,\n",
    "            \"ag_args\": {\"name_suffix\": \"GBM_xt\"},\n",
    "            \"num_leaves\": 128,\n",
    "            \"feature_fraction\": 0.8,\n",
    "            \"bagging_fraction\": 0.8,\n",
    "            \"bagging_freq\": 1,\n",
    "        },\n",
    "    ],\n",
    "    \"CAT\": [\n",
    "        {\n",
    "            \"iterations\": 6000,\n",
    "            \"depth\": 8,\n",
    "            \"learning_rate\": 0.03,\n",
    "            \"l2_leaf_reg\": 3.0,\n",
    "            \"border_count\": 254,\n",
    "            \"random_strength\": 0.5,\n",
    "            \"bagging_temperature\": 0.8,\n",
    "            \"ag_args\": {\"name_suffix\": \"CAT_main\"},\n",
    "        },\n",
    "        {\n",
    "            \"iterations\": 8000,\n",
    "            \"depth\": 10,\n",
    "            \"learning_rate\": 0.02,\n",
    "            \"l2_leaf_reg\": 4.0,\n",
    "            \"border_count\": 254,\n",
    "            \"random_strength\": 0.3,\n",
    "            \"bagging_temperature\": 0.5,\n",
    "            \"ag_args\": {\"name_suffix\": \"CAT_deep\"},\n",
    "        },\n",
    "    ],\n",
    "    \"XGB\": {\n",
    "        \"max_depth\": 8,\n",
    "        \"subsample\": 0.9,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"n_estimators\": 4000,\n",
    "        \"learning_rate\": 0.03,\n",
    "    },\n",
    "    \"NN_TORCH\": {\n",
    "        \"ag_args\": {\"name_suffix\": \"NN_heavy\"},\n",
    "        \"layers\": \"128-64-64\",\n",
    "        \"dropout_prob\": 0.1,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "845a2649-65d2-4b34-b999-7ff4fd6ca40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251116_221138\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2\n",
      "CPU Count:          62\n",
      "Memory Avail:       427.52 GB / 503.46 GB (84.9%)\n",
      "Disk Space Avail:   126.78 GB / 130.00 GB (97.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=2\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "/venv/main/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:1444: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ImportError('ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.10.0,<2.45.0\"`')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"/workspace/121/AutogluonModels/ag-20251116_221138/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_221138/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    36537\n",
      "Train Data Columns: 916\n",
      "Label Column:       target\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    437501.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 122.13 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 594 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 26): ['__nlp__.11 стр москва', '__nlp__.12 корп москва', '__nlp__.13 корп москва', '__nlp__.1с1 москва', '__nlp__.20 корп москва', '__nlp__.22 стр москва', '__nlp__.23а', '__nlp__.30 стр', '__nlp__.32 корп москва', '__nlp__.бул корп москва', '__nlp__.городской округ подольск', '__nlp__.калужское шоссе', '__nlp__.киевское шоссе', '__nlp__.комсомольский просп', '__nlp__.кутузовский просп', '__nlp__.ореховый бул', '__nlp__.пр 12', '__nlp__.просп вернадского', '__nlp__.просп мира', '__nlp__.семёновская ул', '__nlp__.стр 12 москва', '__nlp__.территория', '__nlp__.ул академика', '__nlp__.ул александры', '__nlp__.центральная ул', '__nlp__.южная ул']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 26 | ['__nlp__.11 стр москва', '__nlp__.12 корп москва', '__nlp__.13 корп москва', '__nlp__.1с1 москва', '__nlp__.20 корп москва', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   4 | ['name', 'coordinates', 'category', 'address']\n",
      "\t\t('float', [])    : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n",
      "\t\t('int', [])      : 608 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :   4 | ['name', 'coordinates', 'category', 'address']\n",
      "\t\t('float', [])     : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n",
      "\t\t('int', [])       :  40 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n",
      "\t\t('int', ['bool']) : 568 | ['__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', '__nlp__.10 стр москва', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t890 features in original data used to generate 890 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 100.53 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.89s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM_main'}, 'num_leaves': 64, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1}, {'extra_trees': True, 'ag_args': {'name_suffix': 'GBM_xt'}, 'num_leaves': 128, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1}],\n",
      "\t'CAT': [{'iterations': 6000, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 3.0, 'border_count': 254, 'random_strength': 0.5, 'bagging_temperature': 0.8, 'ag_args': {'name_suffix': 'CAT_main'}}, {'iterations': 8000, 'depth': 10, 'learning_rate': 0.02, 'l2_leaf_reg': 4.0, 'border_count': 254, 'random_strength': 0.3, 'bagging_temperature': 0.5, 'ag_args': {'name_suffix': 'CAT_deep'}}],\n",
      "\t'XGB': [{'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.9, 'n_estimators': 4000, 'learning_rate': 0.03}],\n",
      "\t'NN_TORCH': [{'ag_args': {'name_suffix': 'NN_heavy'}, 'layers': '128-64-64', 'dropout_prob': 0.1}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 6 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_main_BAG_L1 ... Training model for up to 797.62s of the 1795.10s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_main_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_xt_BAG_L1 ... Training model for up to 797.23s of the 1794.70s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_xt_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_main_BAG_L1 ... Training model for up to 796.82s of the 1794.30s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install \"ray>=2.10.0,<2.45.0\"`\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0314\t = Validation score   (-root_mean_squared_error)\n",
      "\t426.5s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_deep_BAG_L1 ... Training model for up to 368.77s of the 1366.25s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0358\t = Validation score   (-root_mean_squared_error)\n",
      "\t324.49s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 42.96s of the 1040.43s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorchNN_heavy_BAG_L1 ... Training model for up to 41.39s of the 1038.87s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1037.85s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_main_BAG_L1': 1.0}\n",
      "\t-1.0314\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 6 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_main_BAG_L2 ... Training model for up to 691.71s of the 1037.81s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_main_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_xt_BAG_L2 ... Training model for up to 691.26s of the 1037.36s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_xt_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_main_BAG_L2 ... Training model for up to 690.79s of the 1036.89s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0257\t = Validation score   (-root_mean_squared_error)\n",
      "\t183.68s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_deep_BAG_L2 ... Training model for up to 505.77s of the 851.87s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0247\t = Validation score   (-root_mean_squared_error)\n",
      "\t290.18s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 214.26s of the 560.36s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorchNN_heavy_BAG_L2 ... Training model for up to 212.63s of the 558.73s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 557.65s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 1.0}\n",
      "\t-1.0247\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 6 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_main_BAG_L3 ... Training model for up to 557.62s of the 557.59s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_main_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_xt_BAG_L3 ... Training model for up to 557.10s of the 557.06s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_xt_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_main_BAG_L3 ... Training model for up to 556.66s of the 556.62s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0257\t = Validation score   (-root_mean_squared_error)\n",
      "\t129.4s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_deep_BAG_L3 ... Training model for up to 425.86s of the 425.83s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0258\t = Validation score   (-root_mean_squared_error)\n",
      "\t211.42s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 213.15s of the 213.11s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused XGBoost_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorchNN_heavy_BAG_L3 ... Training model for up to 211.62s of the 211.58s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 210.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.941, 'CatBoostCAT_deep_BAG_L3': 0.059}\n",
      "\t-1.0247\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1589.57s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 2901.9 rows/s (7308 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_221138/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L4      -1.020582  -1.024687  root_mean_squared_error        1.347988       2.518853  1436.298435                 0.001827                0.000630           0.018928            4       True          9\n",
      "1  CatBoostCAT_deep_BAG_L2      -1.020604  -1.024688  root_mean_squared_error        0.847170       1.545372  1041.173695                 0.264493                0.447902         290.183823            2       True          5\n",
      "2      WeightedEnsemble_L3      -1.020604  -1.024688  root_mean_squared_error        0.848729       1.545838  1041.182635                 0.001559                0.000465           0.008940            3       True          6\n",
      "3  CatBoostCAT_deep_BAG_L3      -1.020867  -1.025821  root_mean_squared_error        1.346161       2.518223  1436.279507                 0.239977                0.419555         211.420836            3       True          8\n",
      "4  CatBoostCAT_main_BAG_L2      -1.021309  -1.025741  root_mean_squared_error        0.841690       1.650766   934.674849                 0.259014                0.553296         183.684977            2       True          4\n",
      "5  CatBoostCAT_main_BAG_L3      -1.021463  -1.025715  root_mean_squared_error        1.338814       2.723049  1354.260983                 0.232631                0.624382         129.402311            3       True          7\n",
      "6  CatBoostCAT_main_BAG_L1      -1.026909  -1.031446  root_mean_squared_error        0.321155       0.636704   426.495583                 0.321155                0.636704         426.495583            1       True          1\n",
      "7      WeightedEnsemble_L2      -1.026909  -1.031446  root_mean_squared_error        0.323346       0.637138   426.504266                 0.002191                0.000434           0.008683            2       True          3\n",
      "8  CatBoostCAT_deep_BAG_L1      -1.029161  -1.035799  root_mean_squared_error        0.261522       0.460766   324.494289                 0.261522                0.460766         324.494289            1       True          2\n",
      "\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t1592s\t = DyStack   runtime |\t5608s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=2.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n",
      "Beginning AutoGluon training ... Time limit = 5608s\n",
      "AutoGluon will save models to \"/workspace/121/AutogluonModels/ag-20251116_221138\"\n",
      "Train Data Rows:    41105\n",
      "Train Data Columns: 916\n",
      "Label Column:       target\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    437969.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 137.40 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 593 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   4 | ['name', 'coordinates', 'category', 'address']\n",
      "\t\t('float', [])    : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n",
      "\t\t('int', [])      : 634 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :   4 | ['name', 'coordinates', 'category', 'address']\n",
      "\t\t('float', [])     : 278 | ['homes_300m', 'works_300m', 'female_300m', 'train_ticket_order_300m', 'mortgage_300m', ...]\n",
      "\t\t('int', [])       :  41 | ['id', 'traffic_300m', 'traffic_1000m', 'address.char_count', 'address.word_count', ...]\n",
      "\t\t('int', ['bool']) : 593 | ['__nlp__.10 корп', '__nlp__.10 корп москва', '__nlp__.10 москва', '__nlp__.10 стр', '__nlp__.10 стр москва', ...]\n",
      "\t5.3s = Fit runtime\n",
      "\t916 features in original data used to generate 916 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 114.16 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'extra_trees': False, 'ag_args': {'name_suffix': 'GBM_main'}, 'num_leaves': 64, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'bagging_freq': 1}, {'extra_trees': True, 'ag_args': {'name_suffix': 'GBM_xt'}, 'num_leaves': 128, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1}],\n",
      "\t'CAT': [{'iterations': 6000, 'depth': 8, 'learning_rate': 0.03, 'l2_leaf_reg': 3.0, 'border_count': 254, 'random_strength': 0.5, 'bagging_temperature': 0.8, 'ag_args': {'name_suffix': 'CAT_main'}}, {'iterations': 8000, 'depth': 10, 'learning_rate': 0.02, 'l2_leaf_reg': 4.0, 'border_count': 254, 'random_strength': 0.3, 'bagging_temperature': 0.5, 'ag_args': {'name_suffix': 'CAT_deep'}}],\n",
      "\t'XGB': [{'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.9, 'n_estimators': 4000, 'learning_rate': 0.03}],\n",
      "\t'NN_TORCH': [{'ag_args': {'name_suffix': 'NN_heavy'}, 'layers': '128-64-64', 'dropout_prob': 0.1}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Fitting 6 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_main_BAG_L1 ... Training model for up to 2489.58s of the 5602.95s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_main_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_xt_BAG_L1 ... Training model for up to 2489.11s of the 5602.49s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_xt_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_main_BAG_L1 ... Training model for up to 2488.64s of the 5602.01s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0259\t = Validation score   (-root_mean_squared_error)\n",
      "\t538.83s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_deep_BAG_L1 ... Training model for up to 1948.19s of the 5061.56s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0222\t = Validation score   (-root_mean_squared_error)\n",
      "\t1653.11s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 292.80s of the 3406.18s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorchNN_heavy_BAG_L1 ... Training model for up to 291.20s of the 3404.57s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3403.52s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L1': 1.0}\n",
      "\t-1.0222\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 6 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_main_BAG_L2 ... Training model for up to 2268.43s of the 3403.48s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_main_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_xt_BAG_L2 ... Training model for up to 2267.99s of the 3403.04s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_xt_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_main_BAG_L2 ... Training model for up to 2267.56s of the 3402.61s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0195\t = Validation score   (-root_mean_squared_error)\n",
      "\t175.95s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_deep_BAG_L2 ... Training model for up to 2090.07s of the 3225.12s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0193\t = Validation score   (-root_mean_squared_error)\n",
      "\t518.58s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1569.84s of the 2704.89s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorchNN_heavy_BAG_L2 ... Training model for up to 1568.24s of the 2703.29s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2702.25s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.9, 'CatBoostCAT_main_BAG_L2': 0.1}\n",
      "\t-1.0193\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 6 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_main_BAG_L3 ... Training model for up to 2702.21s of the 2702.19s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_main_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: LightGBMGBM_xt_BAG_L3 ... Training model for up to 2701.79s of the 2701.77s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_xt_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_main_BAG_L3 ... Training model for up to 2701.38s of the 2701.37s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0204\t = Validation score   (-root_mean_squared_error)\n",
      "\t154.95s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: CatBoostCAT_deep_BAG_L3 ... Training model for up to 2544.97s of the 2544.95s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0205\t = Validation score   (-root_mean_squared_error)\n",
      "\t461.0s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 2082.38s of the 2082.36s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused XGBoost_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import xgboost` failed. A quick tip is to install via `pip install autogluon.tabular[xgboost]==1.4.0`.\n",
      "Fitting model: NeuralNetTorchNN_heavy_BAG_L3 ... Training model for up to 2080.79s of the 2080.77s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tWarning: Exception caused NeuralNetTorchNN_heavy_BAG_L3 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 360.00s of the 2079.70s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.909, 'CatBoostCAT_deep_BAG_L1': 0.091}\n",
      "\t-1.0193\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3528.86s ... Best model: WeightedEnsemble_L4 | Estimated inference throughput: 3871.3 rows/s (8221 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_221138\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "heavy_time_limit = 7200  # 2 часа, под задачу можно меньше/больше\n",
    "\n",
    "predictor_heavy = TabularPredictor(\n",
    "    label=TARGET_COL,\n",
    "    problem_type=\"regression\",\n",
    "    eval_metric=\"mse\",\n",
    ").fit(\n",
    "    train_data=train_ag,\n",
    "    time_limit=heavy_time_limit,\n",
    "    presets=\"best_quality\",          # heavy режим\n",
    "    num_bag_folds=5,                 # бэггинг по фолдам\n",
    "    num_bag_sets=2,                  # повторение бэггинга\n",
    "    num_stack_levels=2,              # двухуровневый stacking\n",
    "    hyperparameters=heavy_hps,\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b5d707e-e031-4347-8aa1-69336fe77ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMGBM_extra_BAG_L1 ... Training model for up to 1800.00s of the 1800.00s of remaining time.\n",
      "\tWarning: Exception caused LightGBMGBM_extra_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "Fitting model: CatBoostCAT_extra_BAG_L1 ... Training model for up to 1799.58s of the 1799.58s of remaining time.\n",
      "\tFitting 10 child models (S1F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy (sequential: cpus=62, gpus=1)\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t-1.0326\t = Validation score   (-root_mean_squared_error)\n",
      "\t867.98s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_2_L2 ... Training model for up to 360.00s of the 929.56s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoostCAT_extra_BAG_L1': 1.0}\n",
      "\t-1.0326\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/workspace/121/AutogluonModels/ag-20251116_221138\")\n"
     ]
    }
   ],
   "source": [
    "extra_hps_heavy = {\n",
    "    \"CAT\": {\n",
    "        \"iterations\": 8000,\n",
    "        \"depth\": 8,\n",
    "        \"learning_rate\": 0.008,\n",
    "        \"l2_leaf_reg\": 3.0,\n",
    "        \"ag_args\": {\"name_suffix\": \"CAT_extra\"},\n",
    "    },\n",
    "    \"GBM\": [\n",
    "        {\n",
    "            \"extra_trees\": False,\n",
    "            \"ag_args\": {\"name_suffix\": \"GBM_extra\"},\n",
    "            \"num_leaves\": 128,\n",
    "            \"feature_fraction\": 0.85,\n",
    "            \"bagging_fraction\": 0.85,\n",
    "            \"bagging_freq\": 1,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "predictor_heavy = predictor_heavy.fit_extra(\n",
    "    hyperparameters=extra_hps_heavy,\n",
    "    ag_args_fit={\"num_gpus\": 1},\n",
    "    time_limit=1800,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "190eb0b3-e770-4803-a3a6-24bb3eb39cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_main_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t47.04s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_deep_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t155.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_extra_BAG_L1_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t83.0s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L1': 1.0}\n",
      "\t0.01s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_main_BAG_L2_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t4.93s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_deep_BAG_L2_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t9.55s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_2_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoostCAT_extra_BAG_L1': 1.0}\n",
      "\t0.0s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.9, 'CatBoostCAT_main_BAG_L2': 0.1}\n",
      "\t0.01s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_main_BAG_L3_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t4.49s\t = Training   runtime\n",
      "Fitting 1 L3 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoostCAT_deep_BAG_L3_FULL ...\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t8.46s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L4_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoostCAT_deep_BAG_L2': 0.909, 'CatBoostCAT_deep_BAG_L1': 0.091}\n",
      "\t0.02s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L4_FULL\" (Previously \"WeightedEnsemble_L4\"). AutoGluon will default to using \"WeightedEnsemble_L4_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 315.99s ... Best model: \"WeightedEnsemble_L4_FULL\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CatBoostCAT_main_BAG_L1': 'CatBoostCAT_main_BAG_L1_FULL',\n",
       " 'CatBoostCAT_deep_BAG_L1': 'CatBoostCAT_deep_BAG_L1_FULL',\n",
       " 'CatBoostCAT_extra_BAG_L1': 'CatBoostCAT_extra_BAG_L1_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL',\n",
       " 'CatBoostCAT_main_BAG_L2': 'CatBoostCAT_main_BAG_L2_FULL',\n",
       " 'CatBoostCAT_deep_BAG_L2': 'CatBoostCAT_deep_BAG_L2_FULL',\n",
       " 'WeightedEnsemble_2_L2': 'WeightedEnsemble_2_L2_FULL',\n",
       " 'WeightedEnsemble_L3': 'WeightedEnsemble_L3_FULL',\n",
       " 'CatBoostCAT_main_BAG_L3': 'CatBoostCAT_main_BAG_L3_FULL',\n",
       " 'CatBoostCAT_deep_BAG_L3': 'CatBoostCAT_deep_BAG_L3_FULL',\n",
       " 'WeightedEnsemble_L4': 'WeightedEnsemble_L4_FULL'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refit_models = predictor_heavy.refit_full()  # вернёт список имён моделей\n",
    "refit_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aeef6e40-a33f-4137-aedc-d3bda5b91e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoostCAT_deep_BAG_L3_FULL</td>\n",
       "      <td>-0.916279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.599813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.043656</td>\n",
       "      <td>0.099124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.463934</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostCAT_main_BAG_L3_FULL</td>\n",
       "      <td>-0.923221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.584995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.072683</td>\n",
       "      <td>0.084306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.492962</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostCAT_deep_BAG_L2_FULL</td>\n",
       "      <td>-0.923662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.411435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.649469</td>\n",
       "      <td>0.100992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.546101</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L3_FULL</td>\n",
       "      <td>-0.924691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.501887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216.589046</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L4_FULL</td>\n",
       "      <td>-0.925978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.413476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.667761</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018292</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoostCAT_main_BAG_L2_FULL</td>\n",
       "      <td>-0.935022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.399697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.033620</td>\n",
       "      <td>0.089254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.930252</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoostCAT_deep_BAG_L3</td>\n",
       "      <td>-0.943104</td>\n",
       "      <td>-1.020547</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.916770</td>\n",
       "      <td>3.570393</td>\n",
       "      <td>3347.472876</td>\n",
       "      <td>0.467275</td>\n",
       "      <td>0.723779</td>\n",
       "      <td>460.999281</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoostCAT_main_BAG_L3</td>\n",
       "      <td>-0.944375</td>\n",
       "      <td>-1.020356</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.881808</td>\n",
       "      <td>3.521692</td>\n",
       "      <td>3041.426079</td>\n",
       "      <td>0.432313</td>\n",
       "      <td>0.675078</td>\n",
       "      <td>154.952484</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoostCAT_deep_BAG_L2</td>\n",
       "      <td>-0.946427</td>\n",
       "      <td>-1.019281</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.014383</td>\n",
       "      <td>2.123481</td>\n",
       "      <td>2710.522289</td>\n",
       "      <td>0.443499</td>\n",
       "      <td>0.746373</td>\n",
       "      <td>518.578130</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-0.946615</td>\n",
       "      <td>-1.019280</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.451519</td>\n",
       "      <td>2.847040</td>\n",
       "      <td>2886.482920</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>-0.947829</td>\n",
       "      <td>-1.019257</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.016348</td>\n",
       "      <td>2.123899</td>\n",
       "      <td>2710.540581</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.018292</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoostCAT_main_BAG_L2</td>\n",
       "      <td>-0.948376</td>\n",
       "      <td>-1.019471</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.005996</td>\n",
       "      <td>2.100241</td>\n",
       "      <td>2367.895465</td>\n",
       "      <td>0.435112</td>\n",
       "      <td>0.723133</td>\n",
       "      <td>175.951306</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatBoostCAT_deep_BAG_L1_FULL</td>\n",
       "      <td>-0.954988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.110367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.067148</td>\n",
       "      <td>0.110367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.067148</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>-0.954988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.076736</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoostCAT_main_BAG_L1_FULL</td>\n",
       "      <td>-0.964836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.200077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.036220</td>\n",
       "      <td>0.200077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.036220</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CatBoostCAT_deep_BAG_L1</td>\n",
       "      <td>-0.965217</td>\n",
       "      <td>-1.022203</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.798954</td>\n",
       "      <td>0.827065</td>\n",
       "      <td>1653.112687</td>\n",
       "      <td>0.798954</td>\n",
       "      <td>0.827065</td>\n",
       "      <td>1653.112687</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.965217</td>\n",
       "      <td>-1.022203</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.800689</td>\n",
       "      <td>0.827510</td>\n",
       "      <td>1653.122275</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CatBoostCAT_main_BAG_L1</td>\n",
       "      <td>-0.973938</td>\n",
       "      <td>-1.025913</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.550043</td>\n",
       "      <td>538.831471</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.550043</td>\n",
       "      <td>538.831471</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CatBoostCAT_extra_BAG_L1_FULL</td>\n",
       "      <td>-0.989324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.130311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.004028</td>\n",
       "      <td>0.130311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.004028</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WeightedEnsemble_2_L2_FULL</td>\n",
       "      <td>-0.989324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.131992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.006668</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoostCAT_extra_BAG_L1</td>\n",
       "      <td>-1.000057</td>\n",
       "      <td>-1.032590</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.115262</td>\n",
       "      <td>0.632822</td>\n",
       "      <td>867.975810</td>\n",
       "      <td>1.115262</td>\n",
       "      <td>0.632822</td>\n",
       "      <td>867.975810</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WeightedEnsemble_2_L2</td>\n",
       "      <td>-1.000057</td>\n",
       "      <td>-1.032590</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.117133</td>\n",
       "      <td>0.633230</td>\n",
       "      <td>867.978451</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  score_test  score_val  \\\n",
       "0    CatBoostCAT_deep_BAG_L3_FULL   -0.916279        NaN   \n",
       "1    CatBoostCAT_main_BAG_L3_FULL   -0.923221        NaN   \n",
       "2    CatBoostCAT_deep_BAG_L2_FULL   -0.923662        NaN   \n",
       "3        WeightedEnsemble_L3_FULL   -0.924691        NaN   \n",
       "4        WeightedEnsemble_L4_FULL   -0.925978        NaN   \n",
       "5    CatBoostCAT_main_BAG_L2_FULL   -0.935022        NaN   \n",
       "6         CatBoostCAT_deep_BAG_L3   -0.943104  -1.020547   \n",
       "7         CatBoostCAT_main_BAG_L3   -0.944375  -1.020356   \n",
       "8         CatBoostCAT_deep_BAG_L2   -0.946427  -1.019281   \n",
       "9             WeightedEnsemble_L3   -0.946615  -1.019280   \n",
       "10            WeightedEnsemble_L4   -0.947829  -1.019257   \n",
       "11        CatBoostCAT_main_BAG_L2   -0.948376  -1.019471   \n",
       "12   CatBoostCAT_deep_BAG_L1_FULL   -0.954988        NaN   \n",
       "13       WeightedEnsemble_L2_FULL   -0.954988        NaN   \n",
       "14   CatBoostCAT_main_BAG_L1_FULL   -0.964836        NaN   \n",
       "15        CatBoostCAT_deep_BAG_L1   -0.965217  -1.022203   \n",
       "16            WeightedEnsemble_L2   -0.965217  -1.022203   \n",
       "17        CatBoostCAT_main_BAG_L1   -0.973938  -1.025913   \n",
       "18  CatBoostCAT_extra_BAG_L1_FULL   -0.989324        NaN   \n",
       "19     WeightedEnsemble_2_L2_FULL   -0.989324        NaN   \n",
       "20       CatBoostCAT_extra_BAG_L1   -1.000057  -1.032590   \n",
       "21          WeightedEnsemble_2_L2   -1.000057  -1.032590   \n",
       "\n",
       "                eval_metric  pred_time_test  pred_time_val     fit_time  \\\n",
       "0   root_mean_squared_error        0.599813            NaN   225.043656   \n",
       "1   root_mean_squared_error        0.584995            NaN   221.072683   \n",
       "2   root_mean_squared_error        0.411435            NaN   211.649469   \n",
       "3   root_mean_squared_error        0.501887            NaN   216.589046   \n",
       "4   root_mean_squared_error        0.413476            NaN   211.667761   \n",
       "5   root_mean_squared_error        0.399697            NaN   207.033620   \n",
       "6   root_mean_squared_error        2.916770       3.570393  3347.472876   \n",
       "7   root_mean_squared_error        2.881808       3.521692  3041.426079   \n",
       "8   root_mean_squared_error        2.014383       2.123481  2710.522289   \n",
       "9   root_mean_squared_error        2.451519       2.847040  2886.482920   \n",
       "10  root_mean_squared_error        2.016348       2.123899  2710.540581   \n",
       "11  root_mean_squared_error        2.005996       2.100241  2367.895465   \n",
       "12  root_mean_squared_error        0.110367            NaN   155.067148   \n",
       "13  root_mean_squared_error        0.112044            NaN   155.076736   \n",
       "14  root_mean_squared_error        0.200077            NaN    47.036220   \n",
       "15  root_mean_squared_error        0.798954       0.827065  1653.112687   \n",
       "16  root_mean_squared_error        0.800689       0.827510  1653.122275   \n",
       "17  root_mean_squared_error        0.771930       0.550043   538.831471   \n",
       "18  root_mean_squared_error        0.130311            NaN    83.004028   \n",
       "19  root_mean_squared_error        0.131992            NaN    83.006668   \n",
       "20  root_mean_squared_error        1.115262       0.632822   867.975810   \n",
       "21  root_mean_squared_error        1.117133       0.633230   867.978451   \n",
       "\n",
       "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0                  0.099124                     NaN           8.463934   \n",
       "1                  0.084306                     NaN           4.492962   \n",
       "2                  0.100992                     NaN           9.546101   \n",
       "3                  0.001198                     NaN           0.009325   \n",
       "4                  0.002040                     NaN           0.018292   \n",
       "5                  0.089254                     NaN           4.930252   \n",
       "6                  0.467275                0.723779         460.999281   \n",
       "7                  0.432313                0.675078         154.952484   \n",
       "8                  0.443499                0.746373         518.578130   \n",
       "9                  0.002024                0.000426           0.009325   \n",
       "10                 0.001966                0.000418           0.018292   \n",
       "11                 0.435112                0.723133         175.951306   \n",
       "12                 0.110367                     NaN         155.067148   \n",
       "13                 0.001678                     NaN           0.009588   \n",
       "14                 0.200077                     NaN          47.036220   \n",
       "15                 0.798954                0.827065        1653.112687   \n",
       "16                 0.001735                0.000446           0.009588   \n",
       "17                 0.771930                0.550043         538.831471   \n",
       "18                 0.130311                     NaN          83.004028   \n",
       "19                 0.001681                     NaN           0.002641   \n",
       "20                 1.115262                0.632822         867.975810   \n",
       "21                 0.001871                0.000409           0.002641   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             3       True         21  \n",
       "1             3       True         20  \n",
       "2             2       True         17  \n",
       "3             3       True         19  \n",
       "4             4       True         22  \n",
       "5             2       True         16  \n",
       "6             3       True          8  \n",
       "7             3       True          7  \n",
       "8             2       True          5  \n",
       "9             3       True          6  \n",
       "10            4       True          9  \n",
       "11            2       True          4  \n",
       "12            1       True         13  \n",
       "13            2       True         15  \n",
       "14            1       True         12  \n",
       "15            1       True          2  \n",
       "16            2       True          3  \n",
       "17            1       True          1  \n",
       "18            1       True         14  \n",
       "19            2       True         18  \n",
       "20            1       True         10  \n",
       "21            2       True         11  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_heavy = predictor_heavy.leaderboard(train_ag, silent=True)\n",
    "lb_heavy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "627f0944-bc16-4f5e-a97e-fe176e7c869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 916 features using 5000 rows with 5 shuffle sets...\n",
      "\t1222.19s\t= Expected runtime (244.44s per shuffle set)\n",
      "\t160.98s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0.256087</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>4.254124e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.268956</td>\n",
       "      <td>0.243218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>2.756245e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.163670</td>\n",
       "      <td>0.122774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.026039</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>6.249724e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.017877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinates</th>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>9.073447e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012996</td>\n",
       "      <td>0.006335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>8.226482e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.004805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_income_1000m</th>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>1.859026e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.003139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_income_300m</th>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>7.712692e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__.москва</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>4.327484e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.symbol_count..</th>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>5.027841e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homes_300m</th>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>1.432752e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.001775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.digit_ratio</th>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>5.269784e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children_goods_for_walks_and_travel_300m</th>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>2.400257e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.001528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.symbol_ratio.</th>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>1.058161e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garden_supplies_300m</th>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>2.900566e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pregnancy_websites_300m</th>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>1.558369e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childrens_sports_300m</th>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>4.294483e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manicure_300m</th>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>4.090548e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_&gt;55_300m</th>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>7.102597e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childrens_websites_1000m</th>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>6.376947e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.word_count</th>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>1.464618e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__nlp__._total_</th>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.256272e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.001118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homes_1000m</th>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>6.389504e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.special_ratio</th>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>6.616075e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childrens_sports_1000m</th>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>3.895437e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mortgage_300m</th>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>5.363154e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laser_hair_removal_300m</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>9.345924e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>works_300m</th>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>5.504926e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer_games_300m</th>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1.100289e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime_1000m</th>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>1.187991e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childrens_transport_300m</th>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>4.111978e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          importance    stddev       p_value  \\\n",
       "category                                    0.256087  0.006250  4.254124e-08   \n",
       "name                                        0.143222  0.009931  2.756245e-06   \n",
       "id                                          0.026039  0.003964  6.249724e-05   \n",
       "coordinates                                 0.009665  0.001618  9.073447e-05   \n",
       "address                                     0.007237  0.001181  8.226482e-05   \n",
       "mean_income_1000m                           0.004080  0.000457  1.859026e-05   \n",
       "mean_income_300m                            0.004065  0.000653  7.712692e-05   \n",
       "__nlp__.москва                              0.003000  0.000750  4.327484e-04   \n",
       "address.symbol_count..                      0.002978  0.000774  5.027841e-04   \n",
       "homes_300m                                  0.002896  0.000545  1.432752e-04   \n",
       "address.digit_ratio                         0.002861  0.000074  5.269784e-08   \n",
       "children_goods_for_walks_and_travel_300m    0.002739  0.000588  2.400257e-04   \n",
       "address.symbol_ratio.                       0.002380  0.000130  1.058161e-06   \n",
       "garden_supplies_300m                        0.002287  0.000516  2.900566e-04   \n",
       "pregnancy_websites_300m                     0.002091  0.000402  1.558369e-04   \n",
       "childrens_sports_300m                       0.001936  0.000483  4.294483e-04   \n",
       "manicure_300m                               0.001917  0.000472  4.090548e-04   \n",
       "age_>55_300m                                0.001594  0.000251  7.102597e-05   \n",
       "childrens_websites_1000m                    0.001506  0.000129  6.376947e-06   \n",
       "address.word_count                          0.001493  0.000516  1.464618e-03   \n",
       "__nlp__._total_                             0.001414  0.000144  1.256272e-05   \n",
       "homes_1000m                                 0.001383  0.000118  6.389504e-06   \n",
       "address.special_ratio                       0.001382  0.000213  6.616075e-05   \n",
       "childrens_sports_1000m                      0.001370  0.000185  3.895437e-05   \n",
       "mortgage_300m                               0.001317  0.000348  5.363154e-04   \n",
       "laser_hair_removal_300m                     0.001315  0.000403  9.345924e-04   \n",
       "works_300m                                  0.001301  0.000192  5.504926e-05   \n",
       "computer_games_300m                         0.001238  0.000218  1.100289e-04   \n",
       "anime_1000m                                 0.001236  0.000222  1.187991e-04   \n",
       "childrens_transport_300m                    0.001222  0.000302  4.111978e-04   \n",
       "\n",
       "                                          n  p99_high   p99_low  \n",
       "category                                  5  0.268956  0.243218  \n",
       "name                                      5  0.163670  0.122774  \n",
       "id                                        5  0.034201  0.017877  \n",
       "coordinates                               5  0.012996  0.006335  \n",
       "address                                   5  0.009669  0.004805  \n",
       "mean_income_1000m                         5  0.005022  0.003139  \n",
       "mean_income_300m                          5  0.005409  0.002721  \n",
       "__nlp__.москва                            5  0.004545  0.001455  \n",
       "address.symbol_count..                    5  0.004572  0.001383  \n",
       "homes_300m                                5  0.004017  0.001775  \n",
       "address.digit_ratio                       5  0.003012  0.002709  \n",
       "children_goods_for_walks_and_travel_300m  5  0.003950  0.001528  \n",
       "address.symbol_ratio.                     5  0.002648  0.002113  \n",
       "garden_supplies_300m                      5  0.003349  0.001226  \n",
       "pregnancy_websites_300m                   5  0.002919  0.001264  \n",
       "childrens_sports_300m                     5  0.002931  0.000941  \n",
       "manicure_300m                             5  0.002890  0.000944  \n",
       "age_>55_300m                              5  0.002110  0.001078  \n",
       "childrens_websites_1000m                  5  0.001771  0.001240  \n",
       "address.word_count                        5  0.002555  0.000432  \n",
       "__nlp__._total_                           5  0.001709  0.001118  \n",
       "homes_1000m                               5  0.001627  0.001139  \n",
       "address.special_ratio                     5  0.001821  0.000943  \n",
       "childrens_sports_1000m                    5  0.001751  0.000989  \n",
       "mortgage_300m                             5  0.002034  0.000600  \n",
       "laser_hair_removal_300m                   5  0.002144  0.000486  \n",
       "works_300m                                5  0.001695  0.000906  \n",
       "computer_games_300m                       5  0.001686  0.000790  \n",
       "anime_1000m                               5  0.001693  0.000780  \n",
       "childrens_transport_300m                  5  0.001843  0.000601  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_heavy = predictor_heavy.feature_importance(train_ag)\n",
    "fi_heavy.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f32734a-c150-48bb-b2b7-ceb0a02bf92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.433025\n",
       "1    3.425081\n",
       "2    4.002472\n",
       "3    3.274601\n",
       "4    2.883332\n",
       "Name: target, dtype: float32"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_heavy = predictor_heavy.predict(test_ag)\n",
    "test_pred_heavy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b22877-b11f-4c2e-b458-407fbae3a6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d319e347-1b29-48e0-8963-4169e79695fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21472</td>\n",
       "      <td>3.433025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9837</td>\n",
       "      <td>3.425081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41791</td>\n",
       "      <td>4.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18441</td>\n",
       "      <td>3.274601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49348</td>\n",
       "      <td>2.883332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target\n",
       "0  21472  3.433025\n",
       "1   9837  3.425081\n",
       "2  41791  4.002472\n",
       "3  18441  3.274601\n",
       "4  49348  2.883332"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предсказания medium (если predictor ещё есть)\n",
    "try:\n",
    "    test_pred_medium = predictor.predict(test_ag)\n",
    "except NameError:\n",
    "    test_pred_medium = None\n",
    "\n",
    "if ID_COL is not None and ID_COL in test.columns:\n",
    "    sub_heavy = test[[ID_COL]].copy()\n",
    "    sub_blend = test[[ID_COL]].copy()\n",
    "else:\n",
    "    sub_heavy = pd.DataFrame()\n",
    "    sub_blend = pd.DataFrame()\n",
    "\n",
    "sub_heavy[TARGET_COL] = test_pred_heavy\n",
    "\n",
    "if test_pred_medium is not None:\n",
    "    test_pred_blend = 0.5 * test_pred_heavy.values + 0.5 * test_pred_medium.values\n",
    "    sub_blend[TARGET_COL] = test_pred_blend\n",
    "else:\n",
    "    sub_blend[TARGET_COL] = test_pred_heavy.values\n",
    "\n",
    "sub_heavy.to_csv(\"submission_ag_heavy.csv\", index=False)\n",
    "sub_blend.to_csv(\"submission_ag_heavy_blend.csv\", index=False)\n",
    "\n",
    "sub_heavy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc05a3-f9cd-4890-a598-c716421bcf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
