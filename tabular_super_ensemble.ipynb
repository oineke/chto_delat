{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc99e50",
   "metadata": {},
   "source": [
    "# Tabular Super-Ensemble: 4 CatBoost + Linear + 2 LightGBM + XGBoost\n",
    "\n",
    "Этот ноутбук:\n",
    "1. Читает табличные данные (`train.csv`, `test.csv`, `sample_submission.csv`)\n",
    "2. Обучает **4 CatBoost** с разными гиперпараметрами\n",
    "3. Делает сабмит из ансамбля этих 4 CatBoost\n",
    "4. Обучает **одну линейную модель** (LinearRegression / LogisticRegression) и делает сабмит\n",
    "5. Обучает **2 LightGBM**\n",
    "6. Обучает **1 XGBoost**\n",
    "7. Делает финальный сабмит из ансамбля **всех моделей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef166b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\".\")\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "SAMPLE_SUB_PATH = DATA_DIR / \"sample_submission.csv\"\n",
    "\n",
    "ID_COL = \"id\"          # имя ID-колонки\n",
    "TARGET_COL = \"target\"  # имя таргета в train\n",
    "\n",
    "TASK_TYPE = \"regression\"   # \"regression\" или \"binary\"\n",
    "\n",
    "OUTPUT_DIR = DATA_DIR / \"submissions_ensemble\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Config OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e84c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# IMPORTS & INSTALLS\n",
    "# ============================\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# CatBoost\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install -q catboost\n",
    "    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "\n",
    "# LightGBM\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install -q lightgbm\n",
    "    import lightgbm as lgb\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install -q xgboost\n",
    "    import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# LOAD DATA\n",
    "# ============================\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "sample_sub = pd.read_csv(SAMPLE_SUB_PATH) if SAMPLE_SUB_PATH.exists() else None\n",
    "\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test shape:\", test.shape)\n",
    "print(\"train columns:\", train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# BASIC CHECKS & FEATURE SPLIT\n",
    "# ============================\n",
    "assert ID_COL in train.columns, f\"{ID_COL} not in train\"\n",
    "assert ID_COL in test.columns, f\"{ID_COL} not in test\"\n",
    "assert TARGET_COL in train.columns, f\"{TARGET_COL} not in train\"\n",
    "\n",
    "# общие фичи\n",
    "common_cols = [c for c in train.columns if c in test.columns]\n",
    "feature_cols = [c for c in common_cols if c != ID_COL]\n",
    "\n",
    "X_train = train[feature_cols].copy()\n",
    "X_test = test[feature_cols].copy()\n",
    "y = train[TARGET_COL].copy()\n",
    "\n",
    "cat_cols = [c for c in feature_cols if str(train[c].dtype) in (\"object\", \"category\")]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"n_num:\", len(num_cols), \"| n_cat:\", len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94043517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# LABEL ENCODING ДЛЯ КАТЕГОРИАЛЬНЫХ\n",
    "# ============================\n",
    "encoders = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    vals = pd.concat([X_train[c], X_test[c]], axis=0).astype(str).fillna(\"missing\")\n",
    "    le.fit(vals)\n",
    "    X_train[c] = le.transform(X_train[c].astype(str).fillna(\"missing\"))\n",
    "    X_test[c] = le.transform(X_test[c].astype(str).fillna(\"missing\"))\n",
    "    encoders[c] = le\n",
    "\n",
    "print(\"Label encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CATBOOST POOLS\n",
    "# ============================\n",
    "cat_idx = [X_train.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "train_pool_cb = Pool(X_train, y, cat_features=cat_idx if cat_idx else None)\n",
    "test_pool_cb = Pool(X_test, cat_features=cat_idx if cat_idx else None)\n",
    "\n",
    "print(\"CatBoost pools ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4 CATBOOST MODELS\n",
    "# ============================\n",
    "cat_models = {}\n",
    "cat_preds_test = {}\n",
    "\n",
    "if TASK_TYPE == \"regression\":\n",
    "    CatModel = CatBoostRegressor\n",
    "    loss = \"RMSE\"\n",
    "    eval_metric = \"RMSE\"\n",
    "else:\n",
    "    CatModel = CatBoostClassifier\n",
    "    loss = \"Logloss\"\n",
    "    eval_metric = \"AUC\"\n",
    "\n",
    "cat_params_list = [\n",
    "    dict(iterations=1000, depth=6, learning_rate=0.05, l2_leaf_reg=3.0, bagging_temperature=0.5, random_strength=1.0),\n",
    "    dict(iterations=2000, depth=8, learning_rate=0.03, l2_leaf_reg=3.0, bagging_temperature=0.8, random_strength=0.5),\n",
    "    dict(iterations=3000, depth=10, learning_rate=0.02, l2_leaf_reg=4.0, bagging_temperature=1.0, random_strength=0.2),\n",
    "    dict(iterations=1500, depth=7, learning_rate=0.04, l2_leaf_reg=2.0, bagging_temperature=0.3, random_strength=1.5),\n",
    "]\n",
    "\n",
    "for i, params in enumerate(cat_params_list, 1):\n",
    "    print(f\"=== CatBoost model {i}/4 ===\")\n",
    "    model_name = f\"catboost_{i}\"\n",
    "    model = CatModel(\n",
    "        loss_function=loss,\n",
    "        eval_metric=eval_metric,\n",
    "        random_seed=42 + i,\n",
    "        verbose=200,\n",
    "        task_type=\"CPU\",  # можно поменять на \"GPU\"\n",
    "        **params,\n",
    "    )\n",
    "    model.fit(train_pool_cb)\n",
    "    if TASK_TYPE == \"regression\":\n",
    "        pred_test = model.predict(test_pool_cb)\n",
    "    else:\n",
    "        pred_test = model.predict_proba(test_pool_cb)[:, 1]\n",
    "    cat_models[model_name] = model\n",
    "    cat_preds_test[model_name] = pred_test\n",
    "\n",
    "print(\"All 4 CatBoost models trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ENSEMBLE CATBOOST SUBMISSION\n",
    "# ============================\n",
    "cat_pred_matrix = np.column_stack(list(cat_preds_test.values()))\n",
    "cat_ens = cat_pred_matrix.mean(axis=1)\n",
    "\n",
    "sub_cat = sample_sub.copy() if sample_sub is not None else pd.DataFrame()\n",
    "if ID_COL in test.columns:\n",
    "    sub_cat[ID_COL] = test[ID_COL].values\n",
    "sub_cat[TARGET_COL] = cat_ens\n",
    "\n",
    "path_cat = OUTPUT_DIR / \"submission_catboost_ensemble.csv\"\n",
    "sub_cat.to_csv(path_cat, index=False)\n",
    "print(\"Saved CatBoost ensemble submission to:\", path_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# LINEAR MODEL (REGRESSION / LOGISTIC)\n",
    "# ============================\n",
    "if TASK_TYPE == \"regression\":\n",
    "    lin_model = LinearRegression()\n",
    "    lin_model.fit(X_train, y)\n",
    "    lin_pred_test = lin_model.predict(X_test)\n",
    "else:\n",
    "    lin_model = LogisticRegression(max_iter=1000)\n",
    "    lin_model.fit(X_train, y)\n",
    "    lin_pred_test = lin_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "sub_lin = sample_sub.copy() if sample_sub is not None else pd.DataFrame()\n",
    "if ID_COL in test.columns:\n",
    "    sub_lin[ID_COL] = test[ID_COL].values\n",
    "sub_lin[TARGET_COL] = lin_pred_test\n",
    "\n",
    "path_lin = OUTPUT_DIR / \"submission_linear.csv\"\n",
    "sub_lin.to_csv(path_lin, index=False)\n",
    "print(\"Saved linear model submission to:\", path_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b69f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2 LIGHTGBM MODELS\n",
    "# ============================\n",
    "lgb_preds_test = {}\n",
    "\n",
    "if TASK_TYPE == \"regression\":\n",
    "    LGBModel = lgb.LGBMRegressor\n",
    "    obj = \"regression\"\n",
    "    metric = \"rmse\"\n",
    "else:\n",
    "    LGBModel = lgb.LGBMClassifier\n",
    "    obj = \"binary\"\n",
    "    metric = \"auc\"\n",
    "\n",
    "lgb_params_list = [\n",
    "    dict(n_estimators=2000, learning_rate=0.03, num_leaves=64, subsample=0.8, colsample_bytree=0.8),\n",
    "    dict(n_estimators=3000, learning_rate=0.02, num_leaves=128, subsample=0.9, colsample_bytree=0.9),\n",
    "]\n",
    "\n",
    "for i, params in enumerate(lgb_params_list, 1):\n",
    "    print(f\"=== LightGBM model {i}/2 ===\")\n",
    "    model_name = f\"lgbm_{i}\"\n",
    "    model = LGBModel(\n",
    "        objective=obj,\n",
    "        **params,\n",
    "        random_state=42 + i,\n",
    "    )\n",
    "    model.fit(X_train, y)\n",
    "    if TASK_TYPE == \"regression\":\n",
    "        pred_test = model.predict(X_test)\n",
    "    else:\n",
    "        pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    lgb_preds_test[model_name] = pred_test\n",
    "\n",
    "print(\"LightGBM models trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# XGBOOST MODEL\n",
    "# ============================\n",
    "xgb_preds_test = {}\n",
    "\n",
    "if TASK_TYPE == \"regression\":\n",
    "    XGBModel = xgb.XGBRegressor\n",
    "    obj = \"reg:squarederror\"\n",
    "    eval_metric = \"rmse\"\n",
    "else:\n",
    "    XGBModel = xgb.XGBClassifier\n",
    "    obj = \"binary:logistic\"\n",
    "    eval_metric = \"auc\"\n",
    "\n",
    "print(\"=== XGBoost model ===\")\n",
    "xgb_model = XGBModel(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=obj,\n",
    "    eval_metric=eval_metric,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "xgb_model.fit(X_train, y)\n",
    "if TASK_TYPE == \"regression\":\n",
    "    xgb_pred_test = xgb_model.predict(X_test)\n",
    "else:\n",
    "    xgb_pred_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "xgb_preds_test[\"xgb_1\"] = xgb_pred_test\n",
    "\n",
    "print(\"XGBoost trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# GLOBAL ENSEMBLE OF ALL MODELS\n",
    "# ============================\n",
    "all_preds = {}\n",
    "\n",
    "# CatBoost (4)\n",
    "all_preds.update(cat_preds_test)\n",
    "# Linear\n",
    "all_preds[\"linear\"] = lin_pred_test\n",
    "# LightGBM (2)\n",
    "all_preds.update(lgb_preds_test)\n",
    "# XGBoost (1)\n",
    "all_preds.update(xgb_preds_test)\n",
    "\n",
    "pred_matrix = np.column_stack(list(all_preds.values()))\n",
    "ens_all = pred_matrix.mean(axis=1)\n",
    "\n",
    "if TASK_TYPE == \"binary\":\n",
    "    ens_all = np.clip(ens_all, 0.0, 1.0)\n",
    "\n",
    "sub_all = sample_sub.copy() if sample_sub is not None else pd.DataFrame()\n",
    "if ID_COL in test.columns:\n",
    "    sub_all[ID_COL] = test[ID_COL].values\n",
    "sub_all[TARGET_COL] = ens_all\n",
    "\n",
    "path_all = OUTPUT_DIR / \"submission_ensemble_all_models.csv\"\n",
    "sub_all.to_csv(path_all, index=False)\n",
    "print(\"Saved global ensemble submission to:\", path_all)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
