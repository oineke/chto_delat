{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\".\")\n",
    "TRAIN_CSV = DATA_DIR / \"train.csv\"\n",
    "TEST_CSV = DATA_DIR / \"test.csv\"\n",
    "SAMPLE_SUB_CSV = DATA_DIR / \"sample_submission.csv\"\n",
    "\n",
    "ID_COL = \"Id\"          # колонка с ID (совпадает с именем картинки без расширения)\n",
    "TARGET_COL = \"target\"  # колонка с таргетом в train\n",
    "\n",
    "IMAGE_TRAIN_DIR = DATA_DIR / \"train_images\"  # папка с train-картинками\n",
    "IMAGE_TEST_DIR = DATA_DIR / \"test_images\"    # папка с test-картинками\n",
    "IMAGE_EXT = \".jpg\"                           # расширение файлов\n",
    "\n",
    "TASK_TYPE = \"regression\"  # \"regression\" или \"binary\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "OUTPUT_EMB_TRAIN = DATA_DIR / \"train_image_embeddings.csv\"\n",
    "OUTPUT_EMB_TEST = DATA_DIR / \"test_image_embeddings.csv\"\n",
    "OUTPUT_SUBMISSION = DATA_DIR / \"submission_catboost_image.csv\"\n",
    "\n",
    "print(\"Config OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS & INSTALLS ===\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# timm для удобного доступа к сверточным/vision моделям\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install -q timm\n",
    "    import timm\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"PyTorch is required for this notebook\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install -q catboost\n",
    "    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "train = pd.read_csv(TRAIN_CSV)\n",
    "test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "sample_sub = pd.read_csv(SAMPLE_SUB_CSV) if SAMPLE_SUB_CSV.exists() else None\n",
    "\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test shape:\", test.shape)\n",
    "print(\"columns:\", train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409633b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMAGE DATASET ===\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Простые аугментации/препроцесс как в STEPA-стиле:\n",
    "img_size = 224\n",
    "\n",
    "img_transform = T.Compose([\n",
    "    T.Resize((img_size, img_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, id_col, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = str(image_dir)\n",
    "        self.id_col = id_col\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = str(row[self.id_col])\n",
    "        fname = image_id + IMAGE_EXT\n",
    "        path = os.path.join(self.image_dir, fname)\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"id\": row[self.id_col],\n",
    "        }\n",
    "\n",
    "def build_loader(df, image_dir):\n",
    "    ds = ImageDataset(df, image_dir=image_dir, id_col=ID_COL, transform=img_transform)\n",
    "    dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    return dl\n",
    "\n",
    "train_loader = build_loader(train, IMAGE_TRAIN_DIR)\n",
    "test_loader = build_loader(test, IMAGE_TEST_DIR)\n",
    "\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BACKBONE MODEL (EMBEDDINGS) ===\n",
    "# По мотивам STEPA: берём предобученную vision-модель из timm,\n",
    "# обрезаем классификационную голову и используем penultimate фичи.\n",
    "\n",
    "backbone_name = \"tf_efficientnet_b0_ns\"  # можно поменять под свою версию STEPA\n",
    "model = timm.create_model(backbone_name, pretrained=True, num_classes=0)  # num_classes=0 -> фичи\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Проверим размер эмбеддинга\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 3, img_size, img_size).to(device)\n",
    "    dummy_emb = model(dummy)\n",
    "    emb_dim = dummy_emb.shape[1]\n",
    "print(\"Embedding dim:\", emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXTRACT EMBEDDINGS ===\n",
    "def extract_embeddings(dataloader):\n",
    "    all_ids = []\n",
    "    all_embs = []\n",
    "    for batch in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            embs = model(images)\n",
    "        embs = embs.cpu().numpy()\n",
    "        all_embs.append(embs)\n",
    "        all_ids.extend(batch[\"id\"])\n",
    "    all_embs = np.concatenate(all_embs, axis=0)\n",
    "    cols = [f\"img_emb_{i}\" for i in range(all_embs.shape[1])]\n",
    "    emb_df = pd.DataFrame(all_embs, columns=cols)\n",
    "    emb_df.insert(0, ID_COL, all_ids)\n",
    "    return emb_df\n",
    "\n",
    "train_emb_df = extract_embeddings(train_loader)\n",
    "test_emb_df = extract_embeddings(test_loader)\n",
    "\n",
    "train_emb_df.to_csv(OUTPUT_EMB_TRAIN, index=False)\n",
    "test_emb_df.to_csv(OUTPUT_EMB_TEST, index=False)\n",
    "\n",
    "print(\"Saved embeddings to:\")\n",
    "print(OUTPUT_EMB_TRAIN)\n",
    "print(OUTPUT_EMB_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MERGE EMBEDDINGS WITH TABULAR DATA ===\n",
    "train_emb_df = pd.read_csv(OUTPUT_EMB_TRAIN)\n",
    "test_emb_df = pd.read_csv(OUTPUT_EMB_TEST)\n",
    "\n",
    "train_merged = train.merge(train_emb_df, on=ID_COL, how=\"inner\")\n",
    "test_merged = test.merge(test_emb_df, on=ID_COL, how=\"inner\")\n",
    "\n",
    "print(\"train_merged shape:\", train_merged.shape)\n",
    "print(\"test_merged shape:\", test_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREPARE DATA FOR CATBOOST ===\n",
    "feature_cols = [c for c in train_merged.columns if c not in [ID_COL, TARGET_COL]]\n",
    "X_train = train_merged[feature_cols].copy()\n",
    "y_train = train_merged[TARGET_COL].copy()\n",
    "X_test = test_merged[feature_cols].copy()\n",
    "\n",
    "cat_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
    "\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype(str)\n",
    "    X_test[c] = X_test[c].astype(str)\n",
    "\n",
    "cat_idx = [X_train.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "print(\"n_features:\", X_train.shape[1])\n",
    "print(\"n_cat_features:\", len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779173dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN CATBOOST ===\n",
    "if TASK_TYPE == \"regression\":\n",
    "    model_cb = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        random_seed=42,\n",
    "        verbose=200,\n",
    "        task_type=\"GPU\" if device == \"cuda\" else \"CPU\",\n",
    "    )\n",
    "else:\n",
    "    model_cb = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        random_seed=42,\n",
    "        verbose=200,\n",
    "        task_type=\"GPU\" if device == \"cuda\" else \"CPU\",\n",
    "    )\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_idx if cat_idx else None)\n",
    "test_pool = Pool(X_test, cat_features=cat_idx if cat_idx else None)\n",
    "\n",
    "model_cb.fit(train_pool)\n",
    "test_pred = model_cb.predict(test_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BUILD SUBMISSION ===\n",
    "if sample_sub is not None and TARGET_COL in sample_sub.columns:\n",
    "    sub = sample_sub.copy()\n",
    "    if ID_COL in sub.columns and ID_COL in test_merged.columns:\n",
    "        sub[ID_COL] = test_merged[ID_COL].values\n",
    "    sub[TARGET_COL] = test_pred\n",
    "else:\n",
    "    if ID_COL in test_merged.columns:\n",
    "        sub = pd.DataFrame({ID_COL: test_merged[ID_COL].values, TARGET_COL: test_pred})\n",
    "    else:\n",
    "        sub = pd.DataFrame({TARGET_COL: test_pred})\n",
    "\n",
    "sub.to_csv(OUTPUT_SUBMISSION, index=False)\n",
    "print(\"Saved submission to:\", OUTPUT_SUBMISSION)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
